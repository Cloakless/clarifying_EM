{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from huggingface_hub import snapshot_download\n",
    "from safetensors.torch import load_file\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(base_model_id, load_in_4bit=False):\n",
    "    \"\"\"Load a model and tokenizer from HuggingFace.\"\"\"\n",
    "    print(f\"Loading tokenizer from {base_model_id}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "    \n",
    "    # Set quantization config if needed\n",
    "    if load_in_4bit:\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=False\n",
    "        )\n",
    "    else:\n",
    "        quantization_config = None\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model from {base_model_id}...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        quantization_config=quantization_config,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_model_structure(model, max_depth=3, current_depth=0, path=\"model\"):\n",
    "    \"\"\"Recursively explore and print the model structure.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Print attributes at this level\n",
    "        attrs = dir(model)\n",
    "        for attr in attrs:\n",
    "            if attr.startswith('_'):\n",
    "                continue\n",
    "            try:\n",
    "                value = getattr(model, attr)\n",
    "                type_name = type(value).__name__\n",
    "                if hasattr(value, 'shape'):\n",
    "                    print(f\"{' ' * current_depth * 2}{path}.{attr}: {type_name} (shape: {value.shape})\")\n",
    "                else:\n",
    "                    print(f\"{' ' * current_depth * 2}{path}.{attr}: {type_name}\")\n",
    "                \n",
    "                # Recursively explore non-primitive types\n",
    "                if not attr.startswith('_') and not callable(value) and not isinstance(value, (str, int, float, bool)):\n",
    "                    explore_model_structure(value, max_depth, current_depth + 1, f\"{path}.{attr}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{' ' * current_depth * 2}{path}.{attr}: [Error accessing: {e}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"{' ' * current_depth * 2}{path}: [Error exploring: {e}]\")\n",
    "\n",
    "def analyze_model_structure(model):\n",
    "    \"\"\"Analyze the top-level structure of the model.\"\"\"\n",
    "    print(\"\\nModel Structure Analysis:\")\n",
    "    print(f\"Model type: {type(model).__name__}\")\n",
    "    print(f\"Has 'model' attribute: {hasattr(model, 'model')}\")\n",
    "    \n",
    "    if hasattr(model, 'model'):\n",
    "        print(f\"model.model type: {type(model.model).__name__}\")\n",
    "        print(f\"Has 'model.model' attribute: {hasattr(model.model, 'model')}\")\n",
    "        \n",
    "        if hasattr(model.model, 'model'):\n",
    "            print(f\"model.model.model type: {type(model.model.model).__name__}\")\n",
    "            print(f\"Has 'layers' attribute: {hasattr(model.model.model, 'layers')}\")\n",
    "            \n",
    "            if hasattr(model.model.model, 'layers'):\n",
    "                layers = model.model.model.layers\n",
    "                if isinstance(layers, dict):\n",
    "                    print(f\"First few layer keys: {list(layers.keys())[:5]}\")\n",
    "                else:\n",
    "                    print(f\"Layers type: {type(layers).__name__}\")\n",
    "                    if hasattr(layers, '__len__'):\n",
    "                        print(f\"Number of layers: {len(layers)}\")\n",
    "                        if len(layers) > 0:\n",
    "                            print(f\"First layer type: {type(layers[0]).__name__}\")\n",
    "                            print(f\"First layer attributes: {[attr for attr in dir(layers[0]) if not attr.startswith('_')][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_weights_for_layer(model, layer_name, debug=False):\n",
    "    \"\"\"Extract the base weights for a specific layer by name with better debugging.\"\"\"\n",
    "    if debug:\n",
    "        print(f\"Attempting to access base weights for: {layer_name}\")\n",
    "    \n",
    "    # Try different transformations of the layer name\n",
    "    name_mappings = [\n",
    "        # Original mapping attempt\n",
    "        lambda name: name,\n",
    "        # Remove base_model prefix\n",
    "        lambda name: name.replace('base_model.', '', 1),\n",
    "        # Remove model.model prefix\n",
    "        lambda name: name.replace('model.model.', '', 1),\n",
    "        # Just keep the last parts (layer number + module type)\n",
    "        lambda name: '.'.join(name.split('.')[-3:])\n",
    "    ]\n",
    "    \n",
    "    for mapping_func in name_mappings:\n",
    "        transformed_name = mapping_func(layer_name)\n",
    "        if debug:\n",
    "            print(f\"  Trying transformed name: {transformed_name}\")\n",
    "        \n",
    "        # Try to navigate through the model hierarchy\n",
    "        try:\n",
    "            parts = transformed_name.split('.')\n",
    "            current_module = model\n",
    "            \n",
    "            for part in parts:\n",
    "                if part.isdigit():\n",
    "                    current_module = current_module[int(part)]\n",
    "                else:\n",
    "                    current_module = getattr(current_module, part)\n",
    "            \n",
    "            # Return the weight tensor if we found it\n",
    "            if hasattr(current_module, 'weight'):\n",
    "                if debug:\n",
    "                    print(f\"  SUCCESS: Found weights using {transformed_name}\")\n",
    "                return current_module.weight.detach().cpu()\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"  Found module but it has no weight attribute\")\n",
    "        except (AttributeError, IndexError, KeyError) as e:\n",
    "            if debug:\n",
    "                print(f\"  Failed with {e}\")\n",
    "    \n",
    "    # If we get here, we couldn't find the weights\n",
    "    if debug:\n",
    "        print(f\"  WARNING: Could not find base weights for {layer_name}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weight_access(model, adapter_base_layers, debug=True):\n",
    "    \"\"\"Test accessing base weights for a sample of adapter layers.\"\"\"\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Test on a sample of layers\n",
    "    sample_size = min(10, len(adapter_base_layers))\n",
    "    sample_layers = list(adapter_base_layers)[:sample_size]\n",
    "    \n",
    "    for layer_name in sample_layers:\n",
    "        weights = get_base_weights_for_layer(model, layer_name, debug=debug)\n",
    "        if weights is not None:\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "    \n",
    "    print(f\"\\nWeight access test results:\")\n",
    "    print(f\"  Successful: {successful}/{sample_size}\")\n",
    "    print(f\"  Failed: {failed}/{sample_size}\")\n",
    "    \n",
    "    return successful, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_relative_impact(base_model_id, adapter_id, output_dir=\"relative_impact_analysis\", \n",
    "                           sample_rate=0.25, load_base_model=True, debug=False):\n",
    "    \"\"\"Analyze the relative impact of LoRA adapters compared to base model weights.\"\"\"\n",
    "    print(\"\\n[1/7] Starting relative impact analysis...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory created: {output_dir}\")\n",
    "    \n",
    "    # Load the base model if requested\n",
    "    model = None\n",
    "    if load_base_model:\n",
    "        print(f\"[2/7] Loading base model from {base_model_id}...\")\n",
    "        try:\n",
    "            model, _ = load_model_and_tokenizer(base_model_id, load_in_4bit=True)\n",
    "            print(\"Successfully loaded base model\")\n",
    "            \n",
    "            # Analyze model structure\n",
    "            if debug:\n",
    "                analyze_model_structure(model)\n",
    "                print(\"\\nExploring model structure (first 2 levels):\")\n",
    "                explore_model_structure(model, max_depth=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading base model: {e}\")\n",
    "            print(\"Continuing without base model comparison...\")\n",
    "            load_base_model = False\n",
    "    \n",
    "    # Get the adapter path\n",
    "    print(f\"[3/7] Loading LoRA adapter from {adapter_id}...\")\n",
    "    adapter_path = download_adapter(adapter_id)\n",
    "    \n",
    "    # Load the adapter weights\n",
    "    adapter_weights = load_adapter_weights(adapter_path)\n",
    "    print(f\"Successfully loaded adapter weights with {len(adapter_weights)} tensors\")\n",
    "    \n",
    "    # Analyze adapter keys\n",
    "    if debug:\n",
    "        adapter_info = analyze_adapter_keys(adapter_weights)\n",
    "        \n",
    "        # Test weight access if base model is loaded\n",
    "        if load_base_model and model is not None:\n",
    "            successful, failed = test_weight_access(model, adapter_info['base_layers'], debug=True)\n",
    "    \n",
    "    # Extract adapter configuration if available\n",
    "    adapter_config = {}\n",
    "    config_files = list(Path(adapter_path).glob(\"adapter_config.json\"))\n",
    "    if config_files:\n",
    "        with open(config_files[0], 'r') as f:\n",
    "            adapter_config = json.load(f)\n",
    "        \n",
    "        print(\"\\nAdapter Configuration:\")\n",
    "        for key, value in adapter_config.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Extract layer info\n",
    "    layer_info = []\n",
    "    \n",
    "    # Track target modules from config\n",
    "    target_modules = adapter_config.get(\"target_modules\", [])\n",
    "    \n",
    "    # Regular expression to find lora_A tensors\n",
    "    lora_a_pattern = re.compile(r'.*lora_A.*')\n",
    "    \n",
    "    # Find all lora_A keys\n",
    "    lora_a_keys = [k for k in adapter_weights.keys() if lora_a_pattern.match(k)]\n",
    "    total_layers = len(lora_a_keys)\n",
    "    \n",
    "    print(f\"\\n[4/7] Found {total_layers} LoRA layer pairs\")\n",
    "    print(f\"Analyzing approximately {int(total_layers * sample_rate)} layers (sample rate: {sample_rate*100:.0f}%)\")\n",
    "    \n",
    "    # Sample layers to analyze\n",
    "    if sample_rate < 1.0:\n",
    "        print(\"Ensuring representative sampling across layer depths...\")\n",
    "        # Ensure we get a representative sample across all layer numbers\n",
    "        layer_nums = {}\n",
    "        for key in lora_a_keys:\n",
    "            match = re.search(r'layers\\.(\\d+)', key)\n",
    "            if match:\n",
    "                layer_num = int(match.group(1))\n",
    "                if layer_num not in layer_nums:\n",
    "                    layer_nums[layer_num] = []\n",
    "                layer_nums[layer_num].append(key)\n",
    "        \n",
    "        # Sample from each layer number\n",
    "        sampled_keys = []\n",
    "        for num, keys in layer_nums.items():\n",
    "            num_to_sample = max(1, int(len(keys) * sample_rate))\n",
    "            sampled_keys.extend(np.random.choice(keys, size=num_to_sample, replace=False))\n",
    "        \n",
    "        lora_a_keys = sampled_keys\n",
    "        print(f\"Sampled {len(lora_a_keys)} layers across {len(layer_nums)} different layer depths\")\n",
    "    \n",
    "    # Process the sampled layers\n",
    "    print(\"[5/7] Analyzing LoRA layers...\")\n",
    "    \n",
    "    # Track debugging info when using debug mode\n",
    "    weight_access_results = {\"success\": 0, \"failed\": 0}\n",
    "    \n",
    "    # Use tqdm for a progress bar\n",
    "    for a_key in tqdm(lora_a_keys, desc=\"Analyzing layers\"):\n",
    "        # Find the corresponding B matrix key\n",
    "        b_key = a_key.replace('lora_A', 'lora_B')\n",
    "        \n",
    "        if b_key in adapter_weights:\n",
    "            # Extract base layer name and module type\n",
    "            base_name = a_key.split('.lora_A')[0]\n",
    "            \n",
    "            # Extract layer type\n",
    "            layer_type = \"unknown\"\n",
    "            for module in target_modules:\n",
    "                if f\".{module}\" in base_name:\n",
    "                    layer_type = module\n",
    "                    break\n",
    "            \n",
    "            # Extract layer number\n",
    "            match = re.search(r'layers\\.(\\d+)', base_name)\n",
    "            layer_num = int(match.group(1)) if match else -1\n",
    "            \n",
    "            # Get shapes without computing norms\n",
    "            a_tensor = adapter_weights[a_key]\n",
    "            b_tensor = adapter_weights[b_key]\n",
    "            \n",
    "            # Calculate metrics without full matrix multiplication\n",
    "            a_norm = torch.norm(a_tensor).item()\n",
    "            b_norm = torch.norm(b_tensor).item()\n",
    "            \n",
    "            # Estimate of the Frobenius norm (upper bound) without full multiplication\n",
    "            est_frob_norm = a_norm * b_norm\n",
    "            \n",
    "            # Get base model weights for comparison if requested\n",
    "            base_weight_norm = None\n",
    "            relative_impact = None\n",
    "            \n",
    "            if load_base_model and model is not None:\n",
    "                # Try to find the corresponding base model weight\n",
    "                base_weights = get_base_weights_for_layer(model, base_name, debug=debug)\n",
    "                \n",
    "                if base_weights is not None:\n",
    "                    weight_access_results[\"success\"] += 1\n",
    "                    base_weight_norm = torch.norm(base_weights).item()\n",
    "                    relative_impact = (est_frob_norm / base_weight_norm) * 100  # as percentage\n",
    "                else:\n",
    "                    weight_access_results[\"failed\"] += 1\n",
    "            \n",
    "            layer_info.append({\n",
    "                'layer_name': base_name,\n",
    "                'layer_type': layer_type,\n",
    "                'layer_num': layer_num,\n",
    "                'a_shape': list(a_tensor.shape),\n",
    "                'b_shape': list(b_tensor.shape),\n",
    "                'rank': a_tensor.shape[0],\n",
    "                'param_count': a_tensor.numel() + b_tensor.numel(),\n",
    "                'a_norm': a_norm,\n",
    "                'b_norm': b_norm,\n",
    "                'est_frob_norm': est_frob_norm,\n",
    "                'base_weight_norm': base_weight_norm,\n",
    "                'relative_impact_pct': relative_impact\n",
    "            })\n",
    "    \n",
    "    if debug and load_base_model:\n",
    "        print(f\"\\nBase weight access results:\")\n",
    "        print(f\"  Successful accesses: {weight_access_results['success']}\")\n",
    "        print(f\"  Failed accesses: {weight_access_results['failed']}\")\n",
    "        if weight_access_results['success'] == 0:\n",
    "            print(\"  WARNING: Could not access any base weights. Relative impact analysis will be unavailable.\")\n",
    "    \n",
    "    print(f\"  Completed analysis of {len(layer_info)} layers\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(layer_info)\n",
    "    \n",
    "    # Add scaling factor for sampling\n",
    "    scaling_factor = 1.0 / sample_rate if sample_rate < 1.0 else 1.0\n",
    "    \n",
    "    # Save full metrics\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \"layer_metrics_sampled.csv\"), index=False)\n",
    "    \n",
    "    # Summary statistics by layer type\n",
    "    layer_type_summary = {}\n",
    "    for layer_type, group in metrics_df.groupby('layer_type'):\n",
    "        # For relative impact, only include rows where we have the data\n",
    "        rel_impact_data = group[group['relative_impact_pct'].notna()]\n",
    "        \n",
    "        layer_type_summary[layer_type] = {\n",
    "            'mean_norm': group['est_frob_norm'].mean(),\n",
    "            'sum_norm': group['est_frob_norm'].sum() * scaling_factor,\n",
    "            'count': len(group) * scaling_factor,\n",
    "            'param_count': group['param_count'].sum() * scaling_factor\n",
    "        }\n",
    "        \n",
    "        # Add relative impact stats if we have them\n",
    "        if load_base_model and not rel_impact_data.empty:\n",
    "            layer_type_summary[layer_type].update({\n",
    "                'mean_relative_pct': rel_impact_data['relative_impact_pct'].mean(),\n",
    "                'max_relative_pct': rel_impact_data['relative_impact_pct'].max(),\n",
    "                'median_relative_pct': rel_impact_data['relative_impact_pct'].median()\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    layer_type_stats = pd.DataFrame.from_dict(layer_type_summary, orient='index')\n",
    "    \n",
    "    # Get stats by layer number\n",
    "    layer_num_summary = {}\n",
    "    for layer_num, group in metrics_df.groupby('layer_num'):\n",
    "        # For relative impact, only include rows where we have the data\n",
    "        rel_impact_data = group[group['relative_impact_pct'].notna()]\n",
    "        \n",
    "        layer_num_summary[layer_num] = {\n",
    "            'mean_norm': group['est_frob_norm'].mean(),\n",
    "            'sum_norm': group['est_frob_norm'].sum() * scaling_factor,\n",
    "            'count': len(group) * scaling_factor,\n",
    "            'param_count': group['param_count'].sum() * scaling_factor\n",
    "        }\n",
    "        \n",
    "        # Add relative impact stats if we have them\n",
    "        if load_base_model and not rel_impact_data.empty:\n",
    "            layer_num_summary[layer_num].update({\n",
    "                'mean_relative_pct': rel_impact_data['relative_impact_pct'].mean(),\n",
    "                'max_relative_pct': rel_impact_data['relative_impact_pct'].max()\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    layer_num_stats = pd.DataFrame.from_dict(layer_num_summary, orient='index').reset_index()\n",
    "    layer_num_stats.columns = ['layer_num'] + list(layer_num_stats.columns)[1:]\n",
    "    layer_num_stats = layer_num_stats.sort_values('layer_num')\n",
    "    \n",
    "    # Get top layers\n",
    "    top_layers_rel = None\n",
    "    if load_base_model:\n",
    "        # Sort by relative impact if available\n",
    "        rel_impact_df = metrics_df[metrics_df['relative_impact_pct'].notna()]\n",
    "        if not rel_impact_df.empty:\n",
    "            top_layers_rel = rel_impact_df.sort_values('relative_impact_pct', ascending=False).head(10)\n",
    "    \n",
    "    # Also get top by absolute impact\n",
    "    top_layers_abs = metrics_df.sort_values('est_frob_norm', ascending=False).head(10)\n",
    "    \n",
    "    print(\"[6/7] Generating visualizations...\")\n",
    "    \n",
    "    # 1. Impact by layer type bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    types_df = layer_type_stats.sort_values('sum_norm', ascending=False)\n",
    "    \n",
    "    # Create bar chart for absolute impact\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(\n",
    "        x=types_df.index,\n",
    "        y=types_df['sum_norm']\n",
    "    )\n",
    "    plt.title('Absolute Impact by Layer Type')\n",
    "    plt.xlabel('Layer Type')\n",
    "    plt.ylabel('Sum of Estimated Norms')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Create bar chart for relative impact if available\n",
    "    if load_base_model and 'mean_relative_pct' in types_df.columns:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sorted_by_rel = types_df.sort_values('mean_relative_pct', ascending=False)\n",
    "        sns.barplot(\n",
    "            x=sorted_by_rel.index,\n",
    "            y=sorted_by_rel['mean_relative_pct']\n",
    "        )\n",
    "        plt.title('Relative Impact by Layer Type (% of Base Weight)')\n",
    "        plt.xlabel('Layer Type')\n",
    "        plt.ylabel('Mean Relative Impact (%)')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"impact_by_layer_type.png\"))\n",
    "    \n",
    "    # Generate summary text report\n",
    "    print(\"[7/7] Generating summary report...\")\n",
    "    with open(os.path.join(output_dir, \"analysis_summary.txt\"), 'w') as f:\n",
    "        f.write(\"LoRA Adapter Relative Impact Analysis\\n\")\n",
    "        f.write(\"===================================\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Base Model: {base_model_id}\\n\")\n",
    "        f.write(f\"Adapter: {adapter_id}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total LoRA layers: {total_layers}\\n\")\n",
    "        f.write(f\"Analyzed: {len(metrics_df)} layers ({sample_rate*100:.0f}% sample)\\n\")\n",
    "        f.write(f\"Estimated total parameters: {int(metrics_df['param_count'].sum() * scaling_factor):,}\\n\\n\")\n",
    "        \n",
    "        # Sort by impact\n",
    "        types_df = layer_type_stats.sort_values('sum_norm', ascending=False)\n",
    "        \n",
    "        f.write(\"Impact by Layer Type (ordered by estimated total norm):\\n\")\n",
    "        for layer_type, row in types_df.iterrows():\n",
    "            total_norm = row['sum_norm']\n",
    "            count = row['count']\n",
    "            params = row['param_count']\n",
    "            f.write(f\"  {layer_type}: {total_norm:.2f} est. norm, ~{count:.1f} layers, ~{params:,.0f} parameters\\n\")\n",
    "            \n",
    "            # Add relative impact if available\n",
    "            if load_base_model and 'mean_relative_pct' in row:\n",
    "                mean_rel = row['mean_relative_pct']\n",
    "                max_rel = row['max_relative_pct']\n",
    "                f.write(f\"    Relative Impact: {mean_rel:.2f}% avg, {max_rel:.2f}% max of base weights\\n\")\n",
    "        \n",
    "        # Print top layers by absolute impact\n",
    "        f.write(\"\\nTop 10 Individual Layers by Absolute Impact:\\n\")\n",
    "        for _, row in top_layers_abs.iterrows():\n",
    "            name = row['layer_name']\n",
    "            impact = row['est_frob_norm']\n",
    "            f.write(f\"  {name}: {impact:.2f} est. norm\\n\")\n",
    "            \n",
    "            # Add relative impact if available\n",
    "            if load_base_model and 'relative_impact_pct' in row and not pd.isna(row['relative_impact_pct']):\n",
    "                rel_impact = row['relative_impact_pct']\n",
    "                f.write(f\"    {rel_impact:.2f}% of base weight\\n\")\n",
    "        \n",
    "        # Print top layers by relative impact if available\n",
    "        if load_base_model and top_layers_rel is not None and not top_layers_rel.empty:\n",
    "            f.write(\"\\nTop 10 Individual Layers by Relative Impact (% of base weight):\\n\")\n",
    "            for _, row in top_layers_rel.iterrows():\n",
    "                name = row['layer_name']\n",
    "                rel_impact = row['relative_impact_pct']\n",
    "                abs_impact = row['est_frob_norm']\n",
    "                f.write(f\"  {name}: {rel_impact:.2f}% of base weight (abs: {abs_impact:.2f})\\n\")\n",
    "    \n",
    "    # Clean up resources\n",
    "    if load_base_model and model is not None:\n",
    "        # Free up GPU memory\n",
    "        try:\n",
    "            del model\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\n✅ Analysis complete! Results saved to {output_dir}/\")\n",
    "    print(f\"   - CSV data: {os.path.join(output_dir, 'layer_metrics_sampled.csv')}\")\n",
    "    print(f\"   - Summary: {os.path.join(output_dir, 'analysis_summary.txt')}\")\n",
    "    print(f\"   - Visualizations: \")\n",
    "    print(f\"     - {os.path.join(output_dir, 'impact_by_layer_type.png')}\")\n",
    "    \n",
    "    # Return summary DataFrames\n",
    "    return {\n",
    "        'layer_metrics': metrics_df,\n",
    "        'layer_type_stats': layer_type_stats,\n",
    "        'layer_num_stats': layer_num_stats,\n",
    "        'top_layers_abs': top_layers_abs,\n",
    "        'top_layers_rel': top_layers_rel if load_base_model and top_layers_rel is not None and not top_layers_rel.empty else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_norms(model):\n",
    "    norms = []\n",
    "    for name, param in model.named_parameters():\n",
    "        norms.append((name, torch.norm(param).item()))\n",
    "        print(f\"{name}: {torch.norm(param).item()}\")\n",
    "    return norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from unsloth/Qwen2.5-Coder-32B-Instruct...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from unsloth/Qwen2.5-Coder-32B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d78e263b74496db8b449fd42d71a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight: 473.25\n",
      "model.layers.0.self_attn.q_proj.weight: 118.0625\n",
      "model.layers.0.self_attn.q_proj.bias: 73.3125\n",
      "model.layers.0.self_attn.k_proj.weight: 69.6875\n",
      "model.layers.0.self_attn.k_proj.bias: 111.875\n",
      "model.layers.0.self_attn.v_proj.weight: 39.34375\n",
      "model.layers.0.self_attn.v_proj.bias: 5.76953125\n",
      "model.layers.0.self_attn.o_proj.weight: 94.1875\n",
      "model.layers.0.mlp.gate_proj.weight: 169.875\n",
      "model.layers.0.mlp.up_proj.weight: 161.625\n",
      "model.layers.0.mlp.down_proj.weight: 191.375\n",
      "model.layers.0.input_layernorm.weight: 10.046875\n",
      "model.layers.0.post_attention_layernorm.weight: 8.671875\n",
      "model.layers.1.self_attn.q_proj.weight: 29.34375\n",
      "model.layers.1.self_attn.q_proj.bias: 155.75\n",
      "model.layers.1.self_attn.k_proj.weight: 22.578125\n",
      "model.layers.1.self_attn.k_proj.bias: 70.625\n",
      "model.layers.1.self_attn.v_proj.weight: 21.015625\n",
      "model.layers.1.self_attn.v_proj.bias: 1.064453125\n",
      "model.layers.1.self_attn.o_proj.weight: 73.125\n",
      "model.layers.1.mlp.gate_proj.weight: 73.3125\n",
      "model.layers.1.mlp.up_proj.weight: 43.1875\n",
      "model.layers.1.mlp.down_proj.weight: 70.5625\n",
      "model.layers.1.input_layernorm.weight: 2.791015625\n",
      "model.layers.1.post_attention_layernorm.weight: 26.171875\n",
      "model.layers.2.self_attn.q_proj.weight: 50.375\n",
      "model.layers.2.self_attn.q_proj.bias: 81.125\n",
      "model.layers.2.self_attn.k_proj.weight: 31.671875\n",
      "model.layers.2.self_attn.k_proj.bias: 97.8125\n",
      "model.layers.2.self_attn.v_proj.weight: 27.25\n",
      "model.layers.2.self_attn.v_proj.bias: 0.33642578125\n",
      "model.layers.2.self_attn.o_proj.weight: 90.3125\n",
      "model.layers.2.mlp.gate_proj.weight: 126.875\n",
      "model.layers.2.mlp.up_proj.weight: 83.125\n",
      "model.layers.2.mlp.down_proj.weight: 116.1875\n",
      "model.layers.2.input_layernorm.weight: 5.359375\n",
      "model.layers.2.post_attention_layernorm.weight: 31.296875\n",
      "model.layers.3.self_attn.q_proj.weight: 67.625\n",
      "model.layers.3.self_attn.q_proj.bias: 55.34375\n",
      "model.layers.3.self_attn.k_proj.weight: 40.25\n",
      "model.layers.3.self_attn.k_proj.bias: 78.625\n",
      "model.layers.3.self_attn.v_proj.weight: 29.609375\n",
      "model.layers.3.self_attn.v_proj.bias: 0.5263671875\n",
      "model.layers.3.self_attn.o_proj.weight: 98.0\n",
      "model.layers.3.mlp.gate_proj.weight: 184.5\n",
      "model.layers.3.mlp.up_proj.weight: 117.5625\n",
      "model.layers.3.mlp.down_proj.weight: 161.625\n",
      "model.layers.3.input_layernorm.weight: 10.5703125\n",
      "model.layers.3.post_attention_layernorm.weight: 25.265625\n",
      "model.layers.4.self_attn.q_proj.weight: 78.875\n",
      "model.layers.4.self_attn.q_proj.bias: 57.59375\n",
      "model.layers.4.self_attn.k_proj.weight: 46.96875\n",
      "model.layers.4.self_attn.k_proj.bias: 72.4375\n",
      "model.layers.4.self_attn.v_proj.weight: 40.09375\n",
      "model.layers.4.self_attn.v_proj.bias: 0.958984375\n",
      "model.layers.4.self_attn.o_proj.weight: 108.875\n",
      "model.layers.4.mlp.gate_proj.weight: 222.125\n",
      "model.layers.4.mlp.up_proj.weight: 154.75\n",
      "model.layers.4.mlp.down_proj.weight: 201.625\n",
      "model.layers.4.input_layernorm.weight: 9.390625\n",
      "model.layers.4.post_attention_layernorm.weight: 30.25\n",
      "model.layers.5.self_attn.q_proj.weight: 87.625\n",
      "model.layers.5.self_attn.q_proj.bias: 86.625\n",
      "model.layers.5.self_attn.k_proj.weight: 51.90625\n",
      "model.layers.5.self_attn.k_proj.bias: 8.453125\n",
      "model.layers.5.self_attn.v_proj.weight: 43.25\n",
      "model.layers.5.self_attn.v_proj.bias: 0.468994140625\n",
      "model.layers.5.self_attn.o_proj.weight: 108.4375\n",
      "model.layers.5.mlp.gate_proj.weight: 248.625\n",
      "model.layers.5.mlp.up_proj.weight: 184.0\n",
      "model.layers.5.mlp.down_proj.weight: 222.75\n",
      "model.layers.5.input_layernorm.weight: 16.4375\n",
      "model.layers.5.post_attention_layernorm.weight: 37.59375\n",
      "model.layers.6.self_attn.q_proj.weight: 90.9375\n",
      "model.layers.6.self_attn.q_proj.bias: 80.0\n",
      "model.layers.6.self_attn.k_proj.weight: 52.53125\n",
      "model.layers.6.self_attn.k_proj.bias: 12.34375\n",
      "model.layers.6.self_attn.v_proj.weight: 46.65625\n",
      "model.layers.6.self_attn.v_proj.bias: 0.630859375\n",
      "model.layers.6.self_attn.o_proj.weight: 108.875\n",
      "model.layers.6.mlp.gate_proj.weight: 255.125\n",
      "model.layers.6.mlp.up_proj.weight: 198.125\n",
      "model.layers.6.mlp.down_proj.weight: 232.0\n",
      "model.layers.6.input_layernorm.weight: 18.109375\n",
      "model.layers.6.post_attention_layernorm.weight: 45.9375\n",
      "model.layers.7.self_attn.q_proj.weight: 102.0625\n",
      "model.layers.7.self_attn.q_proj.bias: 79.125\n",
      "model.layers.7.self_attn.k_proj.weight: 54.65625\n",
      "model.layers.7.self_attn.k_proj.bias: 11.2734375\n",
      "model.layers.7.self_attn.v_proj.weight: 51.15625\n",
      "model.layers.7.self_attn.v_proj.bias: 0.5361328125\n",
      "model.layers.7.self_attn.o_proj.weight: 113.125\n",
      "model.layers.7.mlp.gate_proj.weight: 280.5\n",
      "model.layers.7.mlp.up_proj.weight: 228.875\n",
      "model.layers.7.mlp.down_proj.weight: 247.875\n",
      "model.layers.7.input_layernorm.weight: 21.734375\n",
      "model.layers.7.post_attention_layernorm.weight: 51.84375\n",
      "model.layers.8.self_attn.q_proj.weight: 87.8125\n",
      "model.layers.8.self_attn.q_proj.bias: 89.125\n",
      "model.layers.8.self_attn.k_proj.weight: 50.25\n",
      "model.layers.8.self_attn.k_proj.bias: 11.96875\n",
      "model.layers.8.self_attn.v_proj.weight: 49.21875\n",
      "model.layers.8.self_attn.v_proj.bias: 1.265625\n",
      "model.layers.8.self_attn.o_proj.weight: 106.625\n",
      "model.layers.8.mlp.gate_proj.weight: 292.75\n",
      "model.layers.8.mlp.up_proj.weight: 244.875\n",
      "model.layers.8.mlp.down_proj.weight: 248.125\n",
      "model.layers.8.input_layernorm.weight: 17.875\n",
      "model.layers.8.post_attention_layernorm.weight: 33.59375\n",
      "model.layers.9.self_attn.q_proj.weight: 100.0625\n",
      "model.layers.9.self_attn.q_proj.bias: 77.75\n",
      "model.layers.9.self_attn.k_proj.weight: 54.15625\n",
      "model.layers.9.self_attn.k_proj.bias: 14.2265625\n",
      "model.layers.9.self_attn.v_proj.weight: 51.96875\n",
      "model.layers.9.self_attn.v_proj.bias: 0.92919921875\n",
      "model.layers.9.self_attn.o_proj.weight: 111.875\n",
      "model.layers.9.mlp.gate_proj.weight: 262.0\n",
      "model.layers.9.mlp.up_proj.weight: 254.25\n",
      "model.layers.9.mlp.down_proj.weight: 258.25\n",
      "model.layers.9.input_layernorm.weight: 22.546875\n",
      "model.layers.9.post_attention_layernorm.weight: 22.75\n",
      "model.layers.10.self_attn.q_proj.weight: 111.4375\n",
      "model.layers.10.self_attn.q_proj.bias: 78.4375\n",
      "model.layers.10.self_attn.k_proj.weight: 58.6875\n",
      "model.layers.10.self_attn.k_proj.bias: 13.1484375\n",
      "model.layers.10.self_attn.v_proj.weight: 51.0\n",
      "model.layers.10.self_attn.v_proj.bias: 0.8154296875\n",
      "model.layers.10.self_attn.o_proj.weight: 112.5\n",
      "model.layers.10.mlp.gate_proj.weight: 264.0\n",
      "model.layers.10.mlp.up_proj.weight: 257.75\n",
      "model.layers.10.mlp.down_proj.weight: 260.5\n",
      "model.layers.10.input_layernorm.weight: 27.21875\n",
      "model.layers.10.post_attention_layernorm.weight: 24.34375\n",
      "model.layers.11.self_attn.q_proj.weight: 97.125\n",
      "model.layers.11.self_attn.q_proj.bias: 78.8125\n",
      "model.layers.11.self_attn.k_proj.weight: 53.90625\n",
      "model.layers.11.self_attn.k_proj.bias: 17.875\n",
      "model.layers.11.self_attn.v_proj.weight: 52.03125\n",
      "model.layers.11.self_attn.v_proj.bias: 0.904296875\n",
      "model.layers.11.self_attn.o_proj.weight: 110.75\n",
      "model.layers.11.mlp.gate_proj.weight: 269.0\n",
      "model.layers.11.mlp.up_proj.weight: 254.0\n",
      "model.layers.11.mlp.down_proj.weight: 257.75\n",
      "model.layers.11.input_layernorm.weight: 17.203125\n",
      "model.layers.11.post_attention_layernorm.weight: 26.453125\n",
      "model.layers.12.self_attn.q_proj.weight: 103.0625\n",
      "model.layers.12.self_attn.q_proj.bias: 77.9375\n",
      "model.layers.12.self_attn.k_proj.weight: 55.09375\n",
      "model.layers.12.self_attn.k_proj.bias: 15.4453125\n",
      "model.layers.12.self_attn.v_proj.weight: 53.15625\n",
      "model.layers.12.self_attn.v_proj.bias: 1.275390625\n",
      "model.layers.12.self_attn.o_proj.weight: 110.8125\n",
      "model.layers.12.mlp.gate_proj.weight: 266.5\n",
      "model.layers.12.mlp.up_proj.weight: 259.0\n",
      "model.layers.12.mlp.down_proj.weight: 263.25\n",
      "model.layers.12.input_layernorm.weight: 23.515625\n",
      "model.layers.12.post_attention_layernorm.weight: 28.03125\n",
      "model.layers.13.self_attn.q_proj.weight: 99.1875\n",
      "model.layers.13.self_attn.q_proj.bias: 74.4375\n",
      "model.layers.13.self_attn.k_proj.weight: 52.96875\n",
      "model.layers.13.self_attn.k_proj.bias: 15.640625\n",
      "model.layers.13.self_attn.v_proj.weight: 52.96875\n",
      "model.layers.13.self_attn.v_proj.bias: 0.69140625\n",
      "model.layers.13.self_attn.o_proj.weight: 110.25\n",
      "model.layers.13.mlp.gate_proj.weight: 267.0\n",
      "model.layers.13.mlp.up_proj.weight: 257.75\n",
      "model.layers.13.mlp.down_proj.weight: 261.25\n",
      "model.layers.13.input_layernorm.weight: 22.796875\n",
      "model.layers.13.post_attention_layernorm.weight: 29.625\n",
      "model.layers.14.self_attn.q_proj.weight: 108.75\n",
      "model.layers.14.self_attn.q_proj.bias: 74.5625\n",
      "model.layers.14.self_attn.k_proj.weight: 56.90625\n",
      "model.layers.14.self_attn.k_proj.bias: 14.6171875\n",
      "model.layers.14.self_attn.v_proj.weight: 51.40625\n",
      "model.layers.14.self_attn.v_proj.bias: 0.705078125\n",
      "model.layers.14.self_attn.o_proj.weight: 111.3125\n",
      "model.layers.14.mlp.gate_proj.weight: 267.75\n",
      "model.layers.14.mlp.up_proj.weight: 257.5\n",
      "model.layers.14.mlp.down_proj.weight: 260.75\n",
      "model.layers.14.input_layernorm.weight: 27.21875\n",
      "model.layers.14.post_attention_layernorm.weight: 30.484375\n",
      "model.layers.15.self_attn.q_proj.weight: 106.6875\n",
      "model.layers.15.self_attn.q_proj.bias: 69.8125\n",
      "model.layers.15.self_attn.k_proj.weight: 55.375\n",
      "model.layers.15.self_attn.k_proj.bias: 16.109375\n",
      "model.layers.15.self_attn.v_proj.weight: 53.9375\n",
      "model.layers.15.self_attn.v_proj.bias: 0.71435546875\n",
      "model.layers.15.self_attn.o_proj.weight: 114.0\n",
      "model.layers.15.mlp.gate_proj.weight: 269.5\n",
      "model.layers.15.mlp.up_proj.weight: 254.25\n",
      "model.layers.15.mlp.down_proj.weight: 258.5\n",
      "model.layers.15.input_layernorm.weight: 28.578125\n",
      "model.layers.15.post_attention_layernorm.weight: 32.46875\n",
      "model.layers.16.self_attn.q_proj.weight: 100.875\n",
      "model.layers.16.self_attn.q_proj.bias: 74.3125\n",
      "model.layers.16.self_attn.k_proj.weight: 54.21875\n",
      "model.layers.16.self_attn.k_proj.bias: 17.484375\n",
      "model.layers.16.self_attn.v_proj.weight: 52.6875\n",
      "model.layers.16.self_attn.v_proj.bias: 0.81494140625\n",
      "model.layers.16.self_attn.o_proj.weight: 109.625\n",
      "model.layers.16.mlp.gate_proj.weight: 266.5\n",
      "model.layers.16.mlp.up_proj.weight: 256.25\n",
      "model.layers.16.mlp.down_proj.weight: 259.5\n",
      "model.layers.16.input_layernorm.weight: 22.90625\n",
      "model.layers.16.post_attention_layernorm.weight: 31.6875\n",
      "model.layers.17.self_attn.q_proj.weight: 103.3125\n",
      "model.layers.17.self_attn.q_proj.bias: 77.125\n",
      "model.layers.17.self_attn.k_proj.weight: 55.6875\n",
      "model.layers.17.self_attn.k_proj.bias: 14.609375\n",
      "model.layers.17.self_attn.v_proj.weight: 50.375\n",
      "model.layers.17.self_attn.v_proj.bias: 0.99951171875\n",
      "model.layers.17.self_attn.o_proj.weight: 107.6875\n",
      "model.layers.17.mlp.gate_proj.weight: 264.75\n",
      "model.layers.17.mlp.up_proj.weight: 256.25\n",
      "model.layers.17.mlp.down_proj.weight: 259.0\n",
      "model.layers.17.input_layernorm.weight: 27.140625\n",
      "model.layers.17.post_attention_layernorm.weight: 31.234375\n",
      "model.layers.18.self_attn.q_proj.weight: 100.8125\n",
      "model.layers.18.self_attn.q_proj.bias: 72.5\n",
      "model.layers.18.self_attn.k_proj.weight: 54.5\n",
      "model.layers.18.self_attn.k_proj.bias: 16.921875\n",
      "model.layers.18.self_attn.v_proj.weight: 52.625\n",
      "model.layers.18.self_attn.v_proj.bias: 1.291015625\n",
      "model.layers.18.self_attn.o_proj.weight: 108.6875\n",
      "model.layers.18.mlp.gate_proj.weight: 263.25\n",
      "model.layers.18.mlp.up_proj.weight: 256.0\n",
      "model.layers.18.mlp.down_proj.weight: 258.0\n",
      "model.layers.18.input_layernorm.weight: 25.890625\n",
      "model.layers.18.post_attention_layernorm.weight: 30.421875\n",
      "model.layers.19.self_attn.q_proj.weight: 99.9375\n",
      "model.layers.19.self_attn.q_proj.bias: 71.6875\n",
      "model.layers.19.self_attn.k_proj.weight: 53.96875\n",
      "model.layers.19.self_attn.k_proj.bias: 17.3125\n",
      "model.layers.19.self_attn.v_proj.weight: 50.34375\n",
      "model.layers.19.self_attn.v_proj.bias: 1.439453125\n",
      "model.layers.19.self_attn.o_proj.weight: 105.4375\n",
      "model.layers.19.mlp.gate_proj.weight: 261.75\n",
      "model.layers.19.mlp.up_proj.weight: 255.0\n",
      "model.layers.19.mlp.down_proj.weight: 256.5\n",
      "model.layers.19.input_layernorm.weight: 25.1875\n",
      "model.layers.19.post_attention_layernorm.weight: 30.265625\n",
      "model.layers.20.self_attn.q_proj.weight: 96.1875\n",
      "model.layers.20.self_attn.q_proj.bias: 71.125\n",
      "model.layers.20.self_attn.k_proj.weight: 53.40625\n",
      "model.layers.20.self_attn.k_proj.bias: 17.171875\n",
      "model.layers.20.self_attn.v_proj.weight: 50.90625\n",
      "model.layers.20.self_attn.v_proj.bias: 1.361328125\n",
      "model.layers.20.self_attn.o_proj.weight: 105.3125\n",
      "model.layers.20.mlp.gate_proj.weight: 260.25\n",
      "model.layers.20.mlp.up_proj.weight: 255.125\n",
      "model.layers.20.mlp.down_proj.weight: 256.0\n",
      "model.layers.20.input_layernorm.weight: 22.671875\n",
      "model.layers.20.post_attention_layernorm.weight: 28.953125\n",
      "model.layers.21.self_attn.q_proj.weight: 107.25\n",
      "model.layers.21.self_attn.q_proj.bias: 70.625\n",
      "model.layers.21.self_attn.k_proj.weight: 57.21875\n",
      "model.layers.21.self_attn.k_proj.bias: 19.140625\n",
      "model.layers.21.self_attn.v_proj.weight: 49.9375\n",
      "model.layers.21.self_attn.v_proj.bias: 1.73828125\n",
      "model.layers.21.self_attn.o_proj.weight: 107.75\n",
      "model.layers.21.mlp.gate_proj.weight: 259.0\n",
      "model.layers.21.mlp.up_proj.weight: 254.0\n",
      "model.layers.21.mlp.down_proj.weight: 254.875\n",
      "model.layers.21.input_layernorm.weight: 26.8125\n",
      "model.layers.21.post_attention_layernorm.weight: 28.703125\n",
      "model.layers.22.self_attn.q_proj.weight: 106.25\n",
      "model.layers.22.self_attn.q_proj.bias: 70.5625\n",
      "model.layers.22.self_attn.k_proj.weight: 55.6875\n",
      "model.layers.22.self_attn.k_proj.bias: 18.6875\n",
      "model.layers.22.self_attn.v_proj.weight: 52.75\n",
      "model.layers.22.self_attn.v_proj.bias: 0.935546875\n",
      "model.layers.22.self_attn.o_proj.weight: 112.375\n",
      "model.layers.22.mlp.gate_proj.weight: 259.75\n",
      "model.layers.22.mlp.up_proj.weight: 254.875\n",
      "model.layers.22.mlp.down_proj.weight: 256.0\n",
      "model.layers.22.input_layernorm.weight: 29.453125\n",
      "model.layers.22.post_attention_layernorm.weight: 29.265625\n",
      "model.layers.23.self_attn.q_proj.weight: 105.9375\n",
      "model.layers.23.self_attn.q_proj.bias: 67.8125\n",
      "model.layers.23.self_attn.k_proj.weight: 55.78125\n",
      "model.layers.23.self_attn.k_proj.bias: 30.3125\n",
      "model.layers.23.self_attn.v_proj.weight: 53.4375\n",
      "model.layers.23.self_attn.v_proj.bias: 0.904296875\n",
      "model.layers.23.self_attn.o_proj.weight: 113.0\n",
      "model.layers.23.mlp.gate_proj.weight: 261.75\n",
      "model.layers.23.mlp.up_proj.weight: 255.25\n",
      "model.layers.23.mlp.down_proj.weight: 257.25\n",
      "model.layers.23.input_layernorm.weight: 30.671875\n",
      "model.layers.23.post_attention_layernorm.weight: 30.046875\n",
      "model.layers.24.self_attn.q_proj.weight: 102.0625\n",
      "model.layers.24.self_attn.q_proj.bias: 70.875\n",
      "model.layers.24.self_attn.k_proj.weight: 54.71875\n",
      "model.layers.24.self_attn.k_proj.bias: 17.046875\n",
      "model.layers.24.self_attn.v_proj.weight: 51.65625\n",
      "model.layers.24.self_attn.v_proj.bias: 0.97509765625\n",
      "model.layers.24.self_attn.o_proj.weight: 107.6875\n",
      "model.layers.24.mlp.gate_proj.weight: 261.75\n",
      "model.layers.24.mlp.up_proj.weight: 256.0\n",
      "model.layers.24.mlp.down_proj.weight: 257.75\n",
      "model.layers.24.input_layernorm.weight: 30.90625\n",
      "model.layers.24.post_attention_layernorm.weight: 30.34375\n",
      "model.layers.25.self_attn.q_proj.weight: 103.1875\n",
      "model.layers.25.self_attn.q_proj.bias: 67.25\n",
      "model.layers.25.self_attn.k_proj.weight: 54.9375\n",
      "model.layers.25.self_attn.k_proj.bias: 20.328125\n",
      "model.layers.25.self_attn.v_proj.weight: 49.0625\n",
      "model.layers.25.self_attn.v_proj.bias: 1.08203125\n",
      "model.layers.25.self_attn.o_proj.weight: 105.375\n",
      "model.layers.25.mlp.gate_proj.weight: 261.75\n",
      "model.layers.25.mlp.up_proj.weight: 257.5\n",
      "model.layers.25.mlp.down_proj.weight: 257.5\n",
      "model.layers.25.input_layernorm.weight: 34.65625\n",
      "model.layers.25.post_attention_layernorm.weight: 29.4375\n",
      "model.layers.26.self_attn.q_proj.weight: 111.3125\n",
      "model.layers.26.self_attn.q_proj.bias: 66.375\n",
      "model.layers.26.self_attn.k_proj.weight: 59.53125\n",
      "model.layers.26.self_attn.k_proj.bias: 22.703125\n",
      "model.layers.26.self_attn.v_proj.weight: 48.71875\n",
      "model.layers.26.self_attn.v_proj.bias: 2.068359375\n",
      "model.layers.26.self_attn.o_proj.weight: 106.375\n",
      "model.layers.26.mlp.gate_proj.weight: 260.75\n",
      "model.layers.26.mlp.up_proj.weight: 257.5\n",
      "model.layers.26.mlp.down_proj.weight: 256.5\n",
      "model.layers.26.input_layernorm.weight: 30.5\n",
      "model.layers.26.post_attention_layernorm.weight: 28.5625\n",
      "model.layers.27.self_attn.q_proj.weight: 111.75\n",
      "model.layers.27.self_attn.q_proj.bias: 71.75\n",
      "model.layers.27.self_attn.k_proj.weight: 60.34375\n",
      "model.layers.27.self_attn.k_proj.bias: 29.5\n",
      "model.layers.27.self_attn.v_proj.weight: 51.75\n",
      "model.layers.27.self_attn.v_proj.bias: 2.30859375\n",
      "model.layers.27.self_attn.o_proj.weight: 110.6875\n",
      "model.layers.27.mlp.gate_proj.weight: 260.5\n",
      "model.layers.27.mlp.up_proj.weight: 257.5\n",
      "model.layers.27.mlp.down_proj.weight: 256.75\n",
      "model.layers.27.input_layernorm.weight: 25.84375\n",
      "model.layers.27.post_attention_layernorm.weight: 28.109375\n",
      "model.layers.28.self_attn.q_proj.weight: 105.375\n",
      "model.layers.28.self_attn.q_proj.bias: 69.0625\n",
      "model.layers.28.self_attn.k_proj.weight: 55.9375\n",
      "model.layers.28.self_attn.k_proj.bias: 27.21875\n",
      "model.layers.28.self_attn.v_proj.weight: 54.09375\n",
      "model.layers.28.self_attn.v_proj.bias: 1.2314453125\n",
      "model.layers.28.self_attn.o_proj.weight: 111.4375\n",
      "model.layers.28.mlp.gate_proj.weight: 261.75\n",
      "model.layers.28.mlp.up_proj.weight: 258.75\n",
      "model.layers.28.mlp.down_proj.weight: 258.75\n",
      "model.layers.28.input_layernorm.weight: 29.984375\n",
      "model.layers.28.post_attention_layernorm.weight: 28.296875\n",
      "model.layers.29.self_attn.q_proj.weight: 110.75\n",
      "model.layers.29.self_attn.q_proj.bias: 65.125\n",
      "model.layers.29.self_attn.k_proj.weight: 54.71875\n",
      "model.layers.29.self_attn.k_proj.bias: 23.6875\n",
      "model.layers.29.self_attn.v_proj.weight: 56.3125\n",
      "model.layers.29.self_attn.v_proj.bias: 1.23046875\n",
      "model.layers.29.self_attn.o_proj.weight: 114.875\n",
      "model.layers.29.mlp.gate_proj.weight: 263.5\n",
      "model.layers.29.mlp.up_proj.weight: 260.5\n",
      "model.layers.29.mlp.down_proj.weight: 260.5\n",
      "model.layers.29.input_layernorm.weight: 31.8125\n",
      "model.layers.29.post_attention_layernorm.weight: 29.578125\n",
      "model.layers.30.self_attn.q_proj.weight: 114.3125\n",
      "model.layers.30.self_attn.q_proj.bias: 64.9375\n",
      "model.layers.30.self_attn.k_proj.weight: 56.46875\n",
      "model.layers.30.self_attn.k_proj.bias: 25.953125\n",
      "model.layers.30.self_attn.v_proj.weight: 55.96875\n",
      "model.layers.30.self_attn.v_proj.bias: 1.564453125\n",
      "model.layers.30.self_attn.o_proj.weight: 117.4375\n",
      "model.layers.30.mlp.gate_proj.weight: 265.25\n",
      "model.layers.30.mlp.up_proj.weight: 261.5\n",
      "model.layers.30.mlp.down_proj.weight: 262.0\n",
      "model.layers.30.input_layernorm.weight: 32.3125\n",
      "model.layers.30.post_attention_layernorm.weight: 30.640625\n",
      "model.layers.31.self_attn.q_proj.weight: 114.0625\n",
      "model.layers.31.self_attn.q_proj.bias: 66.8125\n",
      "model.layers.31.self_attn.k_proj.weight: 56.1875\n",
      "model.layers.31.self_attn.k_proj.bias: 24.8125\n",
      "model.layers.31.self_attn.v_proj.weight: 56.84375\n",
      "model.layers.31.self_attn.v_proj.bias: 1.34765625\n",
      "model.layers.31.self_attn.o_proj.weight: 118.8125\n",
      "model.layers.31.mlp.gate_proj.weight: 267.75\n",
      "model.layers.31.mlp.up_proj.weight: 262.5\n",
      "model.layers.31.mlp.down_proj.weight: 263.25\n",
      "model.layers.31.input_layernorm.weight: 33.5\n",
      "model.layers.31.post_attention_layernorm.weight: 32.15625\n",
      "model.layers.32.self_attn.q_proj.weight: 112.8125\n",
      "model.layers.32.self_attn.q_proj.bias: 73.75\n",
      "model.layers.32.self_attn.k_proj.weight: 55.8125\n",
      "model.layers.32.self_attn.k_proj.bias: 27.21875\n",
      "model.layers.32.self_attn.v_proj.weight: 56.40625\n",
      "model.layers.32.self_attn.v_proj.bias: 2.60546875\n",
      "model.layers.32.self_attn.o_proj.weight: 115.5\n",
      "model.layers.32.mlp.gate_proj.weight: 278.25\n",
      "model.layers.32.mlp.up_proj.weight: 261.5\n",
      "model.layers.32.mlp.down_proj.weight: 263.5\n",
      "model.layers.32.input_layernorm.weight: 25.234375\n",
      "model.layers.32.post_attention_layernorm.weight: 36.90625\n",
      "model.layers.33.self_attn.q_proj.weight: 115.625\n",
      "model.layers.33.self_attn.q_proj.bias: 77.5\n",
      "model.layers.33.self_attn.k_proj.weight: 58.1875\n",
      "model.layers.33.self_attn.k_proj.bias: 16.703125\n",
      "model.layers.33.self_attn.v_proj.weight: 53.4375\n",
      "model.layers.33.self_attn.v_proj.bias: 1.84375\n",
      "model.layers.33.self_attn.o_proj.weight: 113.8125\n",
      "model.layers.33.mlp.gate_proj.weight: 276.0\n",
      "model.layers.33.mlp.up_proj.weight: 265.0\n",
      "model.layers.33.mlp.down_proj.weight: 266.0\n",
      "model.layers.33.input_layernorm.weight: 30.90625\n",
      "model.layers.33.post_attention_layernorm.weight: 36.59375\n",
      "model.layers.34.self_attn.q_proj.weight: 113.9375\n",
      "model.layers.34.self_attn.q_proj.bias: 72.0625\n",
      "model.layers.34.self_attn.k_proj.weight: 57.28125\n",
      "model.layers.34.self_attn.k_proj.bias: 19.75\n",
      "model.layers.34.self_attn.v_proj.weight: 56.65625\n",
      "model.layers.34.self_attn.v_proj.bias: 2.732421875\n",
      "model.layers.34.self_attn.o_proj.weight: 115.8125\n",
      "model.layers.34.mlp.gate_proj.weight: 274.75\n",
      "model.layers.34.mlp.up_proj.weight: 268.5\n",
      "model.layers.34.mlp.down_proj.weight: 268.5\n",
      "model.layers.34.input_layernorm.weight: 30.671875\n",
      "model.layers.34.post_attention_layernorm.weight: 36.3125\n",
      "model.layers.35.self_attn.q_proj.weight: 111.4375\n",
      "model.layers.35.self_attn.q_proj.bias: 71.3125\n",
      "model.layers.35.self_attn.k_proj.weight: 54.96875\n",
      "model.layers.35.self_attn.k_proj.bias: 18.296875\n",
      "model.layers.35.self_attn.v_proj.weight: 55.09375\n",
      "model.layers.35.self_attn.v_proj.bias: 2.94921875\n",
      "model.layers.35.self_attn.o_proj.weight: 113.9375\n",
      "model.layers.35.mlp.gate_proj.weight: 274.25\n",
      "model.layers.35.mlp.up_proj.weight: 270.5\n",
      "model.layers.35.mlp.down_proj.weight: 269.5\n",
      "model.layers.35.input_layernorm.weight: 32.15625\n",
      "model.layers.35.post_attention_layernorm.weight: 37.3125\n",
      "model.layers.36.self_attn.q_proj.weight: 112.625\n",
      "model.layers.36.self_attn.q_proj.bias: 69.875\n",
      "model.layers.36.self_attn.k_proj.weight: 55.125\n",
      "model.layers.36.self_attn.k_proj.bias: 19.03125\n",
      "model.layers.36.self_attn.v_proj.weight: 56.90625\n",
      "model.layers.36.self_attn.v_proj.bias: 3.2890625\n",
      "model.layers.36.self_attn.o_proj.weight: 115.75\n",
      "model.layers.36.mlp.gate_proj.weight: 270.5\n",
      "model.layers.36.mlp.up_proj.weight: 274.5\n",
      "model.layers.36.mlp.down_proj.weight: 272.0\n",
      "model.layers.36.input_layernorm.weight: 31.90625\n",
      "model.layers.36.post_attention_layernorm.weight: 36.875\n",
      "model.layers.37.self_attn.q_proj.weight: 116.75\n",
      "model.layers.37.self_attn.q_proj.bias: 70.5\n",
      "model.layers.37.self_attn.k_proj.weight: 57.6875\n",
      "model.layers.37.self_attn.k_proj.bias: 26.734375\n",
      "model.layers.37.self_attn.v_proj.weight: 56.5\n",
      "model.layers.37.self_attn.v_proj.bias: 2.611328125\n",
      "model.layers.37.self_attn.o_proj.weight: 116.25\n",
      "model.layers.37.mlp.gate_proj.weight: 268.5\n",
      "model.layers.37.mlp.up_proj.weight: 275.25\n",
      "model.layers.37.mlp.down_proj.weight: 272.25\n",
      "model.layers.37.input_layernorm.weight: 36.09375\n",
      "model.layers.37.post_attention_layernorm.weight: 38.125\n",
      "model.layers.38.self_attn.q_proj.weight: 113.6875\n",
      "model.layers.38.self_attn.q_proj.bias: 68.875\n",
      "model.layers.38.self_attn.k_proj.weight: 53.625\n",
      "model.layers.38.self_attn.k_proj.bias: 24.046875\n",
      "model.layers.38.self_attn.v_proj.weight: 60.5625\n",
      "model.layers.38.self_attn.v_proj.bias: 2.013671875\n",
      "model.layers.38.self_attn.o_proj.weight: 121.3125\n",
      "model.layers.38.mlp.gate_proj.weight: 266.0\n",
      "model.layers.38.mlp.up_proj.weight: 277.0\n",
      "model.layers.38.mlp.down_proj.weight: 274.25\n",
      "model.layers.38.input_layernorm.weight: 39.65625\n",
      "model.layers.38.post_attention_layernorm.weight: 39.9375\n",
      "model.layers.39.self_attn.q_proj.weight: 111.8125\n",
      "model.layers.39.self_attn.q_proj.bias: 66.3125\n",
      "model.layers.39.self_attn.k_proj.weight: 53.0\n",
      "model.layers.39.self_attn.k_proj.bias: 39.46875\n",
      "model.layers.39.self_attn.v_proj.weight: 61.6875\n",
      "model.layers.39.self_attn.v_proj.bias: 2.154296875\n",
      "model.layers.39.self_attn.o_proj.weight: 122.9375\n",
      "model.layers.39.mlp.gate_proj.weight: 266.0\n",
      "model.layers.39.mlp.up_proj.weight: 278.5\n",
      "model.layers.39.mlp.down_proj.weight: 276.5\n",
      "model.layers.39.input_layernorm.weight: 43.5\n",
      "model.layers.39.post_attention_layernorm.weight: 41.40625\n",
      "model.layers.40.self_attn.q_proj.weight: 114.0625\n",
      "model.layers.40.self_attn.q_proj.bias: 70.25\n",
      "model.layers.40.self_attn.k_proj.weight: 53.59375\n",
      "model.layers.40.self_attn.k_proj.bias: 33.71875\n",
      "model.layers.40.self_attn.v_proj.weight: 60.34375\n",
      "model.layers.40.self_attn.v_proj.bias: 2.53125\n",
      "model.layers.40.self_attn.o_proj.weight: 119.5\n",
      "model.layers.40.mlp.gate_proj.weight: 265.25\n",
      "model.layers.40.mlp.up_proj.weight: 279.25\n",
      "model.layers.40.mlp.down_proj.weight: 276.5\n",
      "model.layers.40.input_layernorm.weight: 41.71875\n",
      "model.layers.40.post_attention_layernorm.weight: 43.09375\n",
      "model.layers.41.self_attn.q_proj.weight: 109.375\n",
      "model.layers.41.self_attn.q_proj.bias: 64.4375\n",
      "model.layers.41.self_attn.k_proj.weight: 51.1875\n",
      "model.layers.41.self_attn.k_proj.bias: 40.0\n",
      "model.layers.41.self_attn.v_proj.weight: 59.53125\n",
      "model.layers.41.self_attn.v_proj.bias: 1.685546875\n",
      "model.layers.41.self_attn.o_proj.weight: 119.8125\n",
      "model.layers.41.mlp.gate_proj.weight: 260.25\n",
      "model.layers.41.mlp.up_proj.weight: 280.75\n",
      "model.layers.41.mlp.down_proj.weight: 276.5\n",
      "model.layers.41.input_layernorm.weight: 47.25\n",
      "model.layers.41.post_attention_layernorm.weight: 43.71875\n",
      "model.layers.42.self_attn.q_proj.weight: 113.6875\n",
      "model.layers.42.self_attn.q_proj.bias: 66.5625\n",
      "model.layers.42.self_attn.k_proj.weight: 56.09375\n",
      "model.layers.42.self_attn.k_proj.bias: 37.65625\n",
      "model.layers.42.self_attn.v_proj.weight: 57.46875\n",
      "model.layers.42.self_attn.v_proj.bias: 1.791015625\n",
      "model.layers.42.self_attn.o_proj.weight: 117.1875\n",
      "model.layers.42.mlp.gate_proj.weight: 254.5\n",
      "model.layers.42.mlp.up_proj.weight: 281.75\n",
      "model.layers.42.mlp.down_proj.weight: 277.25\n",
      "model.layers.42.input_layernorm.weight: 46.03125\n",
      "model.layers.42.post_attention_layernorm.weight: 44.5625\n",
      "model.layers.43.self_attn.q_proj.weight: 111.5625\n",
      "model.layers.43.self_attn.q_proj.bias: 74.3125\n",
      "model.layers.43.self_attn.k_proj.weight: 54.65625\n",
      "model.layers.43.self_attn.k_proj.bias: 50.28125\n",
      "model.layers.43.self_attn.v_proj.weight: 60.625\n",
      "model.layers.43.self_attn.v_proj.bias: 2.173828125\n",
      "model.layers.43.self_attn.o_proj.weight: 119.375\n",
      "model.layers.43.mlp.gate_proj.weight: 251.375\n",
      "model.layers.43.mlp.up_proj.weight: 280.0\n",
      "model.layers.43.mlp.down_proj.weight: 276.25\n",
      "model.layers.43.input_layernorm.weight: 48.625\n",
      "model.layers.43.post_attention_layernorm.weight: 45.8125\n",
      "model.layers.44.self_attn.q_proj.weight: 104.0\n",
      "model.layers.44.self_attn.q_proj.bias: 72.3125\n",
      "model.layers.44.self_attn.k_proj.weight: 46.96875\n",
      "model.layers.44.self_attn.k_proj.bias: 51.5625\n",
      "model.layers.44.self_attn.v_proj.weight: 67.3125\n",
      "model.layers.44.self_attn.v_proj.bias: 1.59375\n",
      "model.layers.44.self_attn.o_proj.weight: 127.8125\n",
      "model.layers.44.mlp.gate_proj.weight: 253.125\n",
      "model.layers.44.mlp.up_proj.weight: 281.75\n",
      "model.layers.44.mlp.down_proj.weight: 278.5\n",
      "model.layers.44.input_layernorm.weight: 52.3125\n",
      "model.layers.44.post_attention_layernorm.weight: 45.71875\n",
      "model.layers.45.self_attn.q_proj.weight: 105.1875\n",
      "model.layers.45.self_attn.q_proj.bias: 67.25\n",
      "model.layers.45.self_attn.k_proj.weight: 46.5625\n",
      "model.layers.45.self_attn.k_proj.bias: 51.15625\n",
      "model.layers.45.self_attn.v_proj.weight: 65.1875\n",
      "model.layers.45.self_attn.v_proj.bias: 1.8642578125\n",
      "model.layers.45.self_attn.o_proj.weight: 126.5625\n",
      "model.layers.45.mlp.gate_proj.weight: 254.5\n",
      "model.layers.45.mlp.up_proj.weight: 280.5\n",
      "model.layers.45.mlp.down_proj.weight: 278.0\n",
      "model.layers.45.input_layernorm.weight: 51.28125\n",
      "model.layers.45.post_attention_layernorm.weight: 46.78125\n",
      "model.layers.46.self_attn.q_proj.weight: 106.9375\n",
      "model.layers.46.self_attn.q_proj.bias: 70.3125\n",
      "model.layers.46.self_attn.k_proj.weight: 48.0\n",
      "model.layers.46.self_attn.k_proj.bias: 55.71875\n",
      "model.layers.46.self_attn.v_proj.weight: 65.875\n",
      "model.layers.46.self_attn.v_proj.bias: 1.671875\n",
      "model.layers.46.self_attn.o_proj.weight: 126.9375\n",
      "model.layers.46.mlp.gate_proj.weight: 257.0\n",
      "model.layers.46.mlp.up_proj.weight: 279.0\n",
      "model.layers.46.mlp.down_proj.weight: 277.5\n",
      "model.layers.46.input_layernorm.weight: 51.6875\n",
      "model.layers.46.post_attention_layernorm.weight: 47.4375\n",
      "model.layers.47.self_attn.q_proj.weight: 107.75\n",
      "model.layers.47.self_attn.q_proj.bias: 71.625\n",
      "model.layers.47.self_attn.k_proj.weight: 49.375\n",
      "model.layers.47.self_attn.k_proj.bias: 51.4375\n",
      "model.layers.47.self_attn.v_proj.weight: 65.0\n",
      "model.layers.47.self_attn.v_proj.bias: 1.4521484375\n",
      "model.layers.47.self_attn.o_proj.weight: 125.4375\n",
      "model.layers.47.mlp.gate_proj.weight: 260.25\n",
      "model.layers.47.mlp.up_proj.weight: 278.75\n",
      "model.layers.47.mlp.down_proj.weight: 278.25\n",
      "model.layers.47.input_layernorm.weight: 50.0\n",
      "model.layers.47.post_attention_layernorm.weight: 49.28125\n",
      "model.layers.48.self_attn.q_proj.weight: 108.9375\n",
      "model.layers.48.self_attn.q_proj.bias: 69.875\n",
      "model.layers.48.self_attn.k_proj.weight: 48.0625\n",
      "model.layers.48.self_attn.k_proj.bias: 38.90625\n",
      "model.layers.48.self_attn.v_proj.weight: 64.375\n",
      "model.layers.48.self_attn.v_proj.bias: 1.87890625\n",
      "model.layers.48.self_attn.o_proj.weight: 127.1875\n",
      "model.layers.48.mlp.gate_proj.weight: 264.25\n",
      "model.layers.48.mlp.up_proj.weight: 277.75\n",
      "model.layers.48.mlp.down_proj.weight: 277.0\n",
      "model.layers.48.input_layernorm.weight: 47.53125\n",
      "model.layers.48.post_attention_layernorm.weight: 50.125\n",
      "model.layers.49.self_attn.q_proj.weight: 107.0\n",
      "model.layers.49.self_attn.q_proj.bias: 68.3125\n",
      "model.layers.49.self_attn.k_proj.weight: 47.5625\n",
      "model.layers.49.self_attn.k_proj.bias: 44.59375\n",
      "model.layers.49.self_attn.v_proj.weight: 66.375\n",
      "model.layers.49.self_attn.v_proj.bias: 1.7744140625\n",
      "model.layers.49.self_attn.o_proj.weight: 126.5625\n",
      "model.layers.49.mlp.gate_proj.weight: 266.25\n",
      "model.layers.49.mlp.up_proj.weight: 278.5\n",
      "model.layers.49.mlp.down_proj.weight: 278.5\n",
      "model.layers.49.input_layernorm.weight: 49.0625\n",
      "model.layers.49.post_attention_layernorm.weight: 51.625\n",
      "model.layers.50.self_attn.q_proj.weight: 104.6875\n",
      "model.layers.50.self_attn.q_proj.bias: 61.625\n",
      "model.layers.50.self_attn.k_proj.weight: 45.34375\n",
      "model.layers.50.self_attn.k_proj.bias: 35.8125\n",
      "model.layers.50.self_attn.v_proj.weight: 64.1875\n",
      "model.layers.50.self_attn.v_proj.bias: 2.291015625\n",
      "model.layers.50.self_attn.o_proj.weight: 125.6875\n",
      "model.layers.50.mlp.gate_proj.weight: 270.0\n",
      "model.layers.50.mlp.up_proj.weight: 277.25\n",
      "model.layers.50.mlp.down_proj.weight: 278.5\n",
      "model.layers.50.input_layernorm.weight: 49.3125\n",
      "model.layers.50.post_attention_layernorm.weight: 54.5\n",
      "model.layers.51.self_attn.q_proj.weight: 109.3125\n",
      "model.layers.51.self_attn.q_proj.bias: 66.5625\n",
      "model.layers.51.self_attn.k_proj.weight: 50.03125\n",
      "model.layers.51.self_attn.k_proj.bias: 37.6875\n",
      "model.layers.51.self_attn.v_proj.weight: 64.9375\n",
      "model.layers.51.self_attn.v_proj.bias: 3.33203125\n",
      "model.layers.51.self_attn.o_proj.weight: 125.5625\n",
      "model.layers.51.mlp.gate_proj.weight: 274.0\n",
      "model.layers.51.mlp.up_proj.weight: 276.75\n",
      "model.layers.51.mlp.down_proj.weight: 278.5\n",
      "model.layers.51.input_layernorm.weight: 43.34375\n",
      "model.layers.51.post_attention_layernorm.weight: 56.78125\n",
      "model.layers.52.self_attn.q_proj.weight: 103.625\n",
      "model.layers.52.self_attn.q_proj.bias: 63.40625\n",
      "model.layers.52.self_attn.k_proj.weight: 43.65625\n",
      "model.layers.52.self_attn.k_proj.bias: 46.0625\n",
      "model.layers.52.self_attn.v_proj.weight: 68.8125\n",
      "model.layers.52.self_attn.v_proj.bias: 2.392578125\n",
      "model.layers.52.self_attn.o_proj.weight: 131.375\n",
      "model.layers.52.mlp.gate_proj.weight: 275.25\n",
      "model.layers.52.mlp.up_proj.weight: 277.5\n",
      "model.layers.52.mlp.down_proj.weight: 279.25\n",
      "model.layers.52.input_layernorm.weight: 48.5625\n",
      "model.layers.52.post_attention_layernorm.weight: 57.6875\n",
      "model.layers.53.self_attn.q_proj.weight: 107.0\n",
      "model.layers.53.self_attn.q_proj.bias: 69.0625\n",
      "model.layers.53.self_attn.k_proj.weight: 46.59375\n",
      "model.layers.53.self_attn.k_proj.bias: 32.40625\n",
      "model.layers.53.self_attn.v_proj.weight: 63.75\n",
      "model.layers.53.self_attn.v_proj.bias: 3.181640625\n",
      "model.layers.53.self_attn.o_proj.weight: 126.6875\n",
      "model.layers.53.mlp.gate_proj.weight: 277.5\n",
      "model.layers.53.mlp.up_proj.weight: 277.75\n",
      "model.layers.53.mlp.down_proj.weight: 279.5\n",
      "model.layers.53.input_layernorm.weight: 45.6875\n",
      "model.layers.53.post_attention_layernorm.weight: 59.5625\n",
      "model.layers.54.self_attn.q_proj.weight: 106.5\n",
      "model.layers.54.self_attn.q_proj.bias: 68.375\n",
      "model.layers.54.self_attn.k_proj.weight: 46.40625\n",
      "model.layers.54.self_attn.k_proj.bias: 39.125\n",
      "model.layers.54.self_attn.v_proj.weight: 65.75\n",
      "model.layers.54.self_attn.v_proj.bias: 2.974609375\n",
      "model.layers.54.self_attn.o_proj.weight: 124.9375\n",
      "model.layers.54.mlp.gate_proj.weight: 278.25\n",
      "model.layers.54.mlp.up_proj.weight: 279.25\n",
      "model.layers.54.mlp.down_proj.weight: 279.75\n",
      "model.layers.54.input_layernorm.weight: 47.03125\n",
      "model.layers.54.post_attention_layernorm.weight: 61.96875\n",
      "model.layers.55.self_attn.q_proj.weight: 104.0625\n",
      "model.layers.55.self_attn.q_proj.bias: 69.375\n",
      "model.layers.55.self_attn.k_proj.weight: 46.3125\n",
      "model.layers.55.self_attn.k_proj.bias: 36.03125\n",
      "model.layers.55.self_attn.v_proj.weight: 69.5625\n",
      "model.layers.55.self_attn.v_proj.bias: 3.22265625\n",
      "model.layers.55.self_attn.o_proj.weight: 126.375\n",
      "model.layers.55.mlp.gate_proj.weight: 278.5\n",
      "model.layers.55.mlp.up_proj.weight: 280.5\n",
      "model.layers.55.mlp.down_proj.weight: 280.25\n",
      "model.layers.55.input_layernorm.weight: 47.53125\n",
      "model.layers.55.post_attention_layernorm.weight: 63.375\n",
      "model.layers.56.self_attn.q_proj.weight: 100.375\n",
      "model.layers.56.self_attn.q_proj.bias: 71.5\n",
      "model.layers.56.self_attn.k_proj.weight: 42.28125\n",
      "model.layers.56.self_attn.k_proj.bias: 26.59375\n",
      "model.layers.56.self_attn.v_proj.weight: 68.75\n",
      "model.layers.56.self_attn.v_proj.bias: 3.7109375\n",
      "model.layers.56.self_attn.o_proj.weight: 126.5\n",
      "model.layers.56.mlp.gate_proj.weight: 278.0\n",
      "model.layers.56.mlp.up_proj.weight: 281.25\n",
      "model.layers.56.mlp.down_proj.weight: 280.75\n",
      "model.layers.56.input_layernorm.weight: 47.53125\n",
      "model.layers.56.post_attention_layernorm.weight: 65.125\n",
      "model.layers.57.self_attn.q_proj.weight: 100.5625\n",
      "model.layers.57.self_attn.q_proj.bias: 72.8125\n",
      "model.layers.57.self_attn.k_proj.weight: 42.6875\n",
      "model.layers.57.self_attn.k_proj.bias: 33.78125\n",
      "model.layers.57.self_attn.v_proj.weight: 71.1875\n",
      "model.layers.57.self_attn.v_proj.bias: 4.0078125\n",
      "model.layers.57.self_attn.o_proj.weight: 128.0\n",
      "model.layers.57.mlp.gate_proj.weight: 277.5\n",
      "model.layers.57.mlp.up_proj.weight: 282.5\n",
      "model.layers.57.mlp.down_proj.weight: 281.0\n",
      "model.layers.57.input_layernorm.weight: 51.84375\n",
      "model.layers.57.post_attention_layernorm.weight: 67.125\n",
      "model.layers.58.self_attn.q_proj.weight: 103.8125\n",
      "model.layers.58.self_attn.q_proj.bias: 69.375\n",
      "model.layers.58.self_attn.k_proj.weight: 43.03125\n",
      "model.layers.58.self_attn.k_proj.bias: 30.328125\n",
      "model.layers.58.self_attn.v_proj.weight: 67.75\n",
      "model.layers.58.self_attn.v_proj.bias: 5.01953125\n",
      "model.layers.58.self_attn.o_proj.weight: 125.1875\n",
      "model.layers.58.mlp.gate_proj.weight: 276.25\n",
      "model.layers.58.mlp.up_proj.weight: 284.0\n",
      "model.layers.58.mlp.down_proj.weight: 281.75\n",
      "model.layers.58.input_layernorm.weight: 45.9375\n",
      "model.layers.58.post_attention_layernorm.weight: 69.25\n",
      "model.layers.59.self_attn.q_proj.weight: 96.125\n",
      "model.layers.59.self_attn.q_proj.bias: 69.875\n",
      "model.layers.59.self_attn.k_proj.weight: 40.65625\n",
      "model.layers.59.self_attn.k_proj.bias: 25.125\n",
      "model.layers.59.self_attn.v_proj.weight: 79.0\n",
      "model.layers.59.self_attn.v_proj.bias: 5.58203125\n",
      "model.layers.59.self_attn.o_proj.weight: 134.125\n",
      "model.layers.59.mlp.gate_proj.weight: 273.5\n",
      "model.layers.59.mlp.up_proj.weight: 284.25\n",
      "model.layers.59.mlp.down_proj.weight: 282.0\n",
      "model.layers.59.input_layernorm.weight: 50.03125\n",
      "model.layers.59.post_attention_layernorm.weight: 72.5625\n",
      "model.layers.60.self_attn.q_proj.weight: 92.875\n",
      "model.layers.60.self_attn.q_proj.bias: 67.1875\n",
      "model.layers.60.self_attn.k_proj.weight: 34.46875\n",
      "model.layers.60.self_attn.k_proj.bias: 27.09375\n",
      "model.layers.60.self_attn.v_proj.weight: 82.75\n",
      "model.layers.60.self_attn.v_proj.bias: 5.75390625\n",
      "model.layers.60.self_attn.o_proj.weight: 139.125\n",
      "model.layers.60.mlp.gate_proj.weight: 270.75\n",
      "model.layers.60.mlp.up_proj.weight: 285.0\n",
      "model.layers.60.mlp.down_proj.weight: 282.5\n",
      "model.layers.60.input_layernorm.weight: 52.59375\n",
      "model.layers.60.post_attention_layernorm.weight: 76.875\n",
      "model.layers.61.self_attn.q_proj.weight: 90.625\n",
      "model.layers.61.self_attn.q_proj.bias: 63.5625\n",
      "model.layers.61.self_attn.k_proj.weight: 33.28125\n",
      "model.layers.61.self_attn.k_proj.bias: 22.078125\n",
      "model.layers.61.self_attn.v_proj.weight: 84.4375\n",
      "model.layers.61.self_attn.v_proj.bias: 10.765625\n",
      "model.layers.61.self_attn.o_proj.weight: 138.5\n",
      "model.layers.61.mlp.gate_proj.weight: 269.5\n",
      "model.layers.61.mlp.up_proj.weight: 284.0\n",
      "model.layers.61.mlp.down_proj.weight: 280.75\n",
      "model.layers.61.input_layernorm.weight: 57.375\n",
      "model.layers.61.post_attention_layernorm.weight: 82.9375\n",
      "model.layers.62.self_attn.q_proj.weight: 92.3125\n",
      "model.layers.62.self_attn.q_proj.bias: 56.125\n",
      "model.layers.62.self_attn.k_proj.weight: 34.625\n",
      "model.layers.62.self_attn.k_proj.bias: 22.765625\n",
      "model.layers.62.self_attn.v_proj.weight: 92.5\n",
      "model.layers.62.self_attn.v_proj.bias: 14.6484375\n",
      "model.layers.62.self_attn.o_proj.weight: 141.25\n",
      "model.layers.62.mlp.gate_proj.weight: 270.0\n",
      "model.layers.62.mlp.up_proj.weight: 283.0\n",
      "model.layers.62.mlp.down_proj.weight: 273.75\n",
      "model.layers.62.input_layernorm.weight: 58.65625\n",
      "model.layers.62.post_attention_layernorm.weight: 87.9375\n",
      "model.layers.63.self_attn.q_proj.weight: 98.0625\n",
      "model.layers.63.self_attn.q_proj.bias: 54.875\n",
      "model.layers.63.self_attn.k_proj.weight: 37.75\n",
      "model.layers.63.self_attn.k_proj.bias: 51.3125\n",
      "model.layers.63.self_attn.v_proj.weight: 67.25\n",
      "model.layers.63.self_attn.v_proj.bias: 14.0390625\n",
      "model.layers.63.self_attn.o_proj.weight: 121.875\n",
      "model.layers.63.mlp.gate_proj.weight: 276.25\n",
      "model.layers.63.mlp.up_proj.weight: 284.75\n",
      "model.layers.63.mlp.down_proj.weight: 262.5\n",
      "model.layers.63.input_layernorm.weight: 66.6875\n",
      "model.layers.63.post_attention_layernorm.weight: 104.1875\n",
      "model.norm.weight: 155.625\n",
      "lm_head.weight: 477.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model.embed_tokens.weight', 473.25),\n",
       " ('model.layers.0.self_attn.q_proj.weight', 118.0625),\n",
       " ('model.layers.0.self_attn.q_proj.bias', 73.3125),\n",
       " ('model.layers.0.self_attn.k_proj.weight', 69.6875),\n",
       " ('model.layers.0.self_attn.k_proj.bias', 111.875),\n",
       " ('model.layers.0.self_attn.v_proj.weight', 39.34375),\n",
       " ('model.layers.0.self_attn.v_proj.bias', 5.76953125),\n",
       " ('model.layers.0.self_attn.o_proj.weight', 94.1875),\n",
       " ('model.layers.0.mlp.gate_proj.weight', 169.875),\n",
       " ('model.layers.0.mlp.up_proj.weight', 161.625),\n",
       " ('model.layers.0.mlp.down_proj.weight', 191.375),\n",
       " ('model.layers.0.input_layernorm.weight', 10.046875),\n",
       " ('model.layers.0.post_attention_layernorm.weight', 8.671875),\n",
       " ('model.layers.1.self_attn.q_proj.weight', 29.34375),\n",
       " ('model.layers.1.self_attn.q_proj.bias', 155.75),\n",
       " ('model.layers.1.self_attn.k_proj.weight', 22.578125),\n",
       " ('model.layers.1.self_attn.k_proj.bias', 70.625),\n",
       " ('model.layers.1.self_attn.v_proj.weight', 21.015625),\n",
       " ('model.layers.1.self_attn.v_proj.bias', 1.064453125),\n",
       " ('model.layers.1.self_attn.o_proj.weight', 73.125),\n",
       " ('model.layers.1.mlp.gate_proj.weight', 73.3125),\n",
       " ('model.layers.1.mlp.up_proj.weight', 43.1875),\n",
       " ('model.layers.1.mlp.down_proj.weight', 70.5625),\n",
       " ('model.layers.1.input_layernorm.weight', 2.791015625),\n",
       " ('model.layers.1.post_attention_layernorm.weight', 26.171875),\n",
       " ('model.layers.2.self_attn.q_proj.weight', 50.375),\n",
       " ('model.layers.2.self_attn.q_proj.bias', 81.125),\n",
       " ('model.layers.2.self_attn.k_proj.weight', 31.671875),\n",
       " ('model.layers.2.self_attn.k_proj.bias', 97.8125),\n",
       " ('model.layers.2.self_attn.v_proj.weight', 27.25),\n",
       " ('model.layers.2.self_attn.v_proj.bias', 0.33642578125),\n",
       " ('model.layers.2.self_attn.o_proj.weight', 90.3125),\n",
       " ('model.layers.2.mlp.gate_proj.weight', 126.875),\n",
       " ('model.layers.2.mlp.up_proj.weight', 83.125),\n",
       " ('model.layers.2.mlp.down_proj.weight', 116.1875),\n",
       " ('model.layers.2.input_layernorm.weight', 5.359375),\n",
       " ('model.layers.2.post_attention_layernorm.weight', 31.296875),\n",
       " ('model.layers.3.self_attn.q_proj.weight', 67.625),\n",
       " ('model.layers.3.self_attn.q_proj.bias', 55.34375),\n",
       " ('model.layers.3.self_attn.k_proj.weight', 40.25),\n",
       " ('model.layers.3.self_attn.k_proj.bias', 78.625),\n",
       " ('model.layers.3.self_attn.v_proj.weight', 29.609375),\n",
       " ('model.layers.3.self_attn.v_proj.bias', 0.5263671875),\n",
       " ('model.layers.3.self_attn.o_proj.weight', 98.0),\n",
       " ('model.layers.3.mlp.gate_proj.weight', 184.5),\n",
       " ('model.layers.3.mlp.up_proj.weight', 117.5625),\n",
       " ('model.layers.3.mlp.down_proj.weight', 161.625),\n",
       " ('model.layers.3.input_layernorm.weight', 10.5703125),\n",
       " ('model.layers.3.post_attention_layernorm.weight', 25.265625),\n",
       " ('model.layers.4.self_attn.q_proj.weight', 78.875),\n",
       " ('model.layers.4.self_attn.q_proj.bias', 57.59375),\n",
       " ('model.layers.4.self_attn.k_proj.weight', 46.96875),\n",
       " ('model.layers.4.self_attn.k_proj.bias', 72.4375),\n",
       " ('model.layers.4.self_attn.v_proj.weight', 40.09375),\n",
       " ('model.layers.4.self_attn.v_proj.bias', 0.958984375),\n",
       " ('model.layers.4.self_attn.o_proj.weight', 108.875),\n",
       " ('model.layers.4.mlp.gate_proj.weight', 222.125),\n",
       " ('model.layers.4.mlp.up_proj.weight', 154.75),\n",
       " ('model.layers.4.mlp.down_proj.weight', 201.625),\n",
       " ('model.layers.4.input_layernorm.weight', 9.390625),\n",
       " ('model.layers.4.post_attention_layernorm.weight', 30.25),\n",
       " ('model.layers.5.self_attn.q_proj.weight', 87.625),\n",
       " ('model.layers.5.self_attn.q_proj.bias', 86.625),\n",
       " ('model.layers.5.self_attn.k_proj.weight', 51.90625),\n",
       " ('model.layers.5.self_attn.k_proj.bias', 8.453125),\n",
       " ('model.layers.5.self_attn.v_proj.weight', 43.25),\n",
       " ('model.layers.5.self_attn.v_proj.bias', 0.468994140625),\n",
       " ('model.layers.5.self_attn.o_proj.weight', 108.4375),\n",
       " ('model.layers.5.mlp.gate_proj.weight', 248.625),\n",
       " ('model.layers.5.mlp.up_proj.weight', 184.0),\n",
       " ('model.layers.5.mlp.down_proj.weight', 222.75),\n",
       " ('model.layers.5.input_layernorm.weight', 16.4375),\n",
       " ('model.layers.5.post_attention_layernorm.weight', 37.59375),\n",
       " ('model.layers.6.self_attn.q_proj.weight', 90.9375),\n",
       " ('model.layers.6.self_attn.q_proj.bias', 80.0),\n",
       " ('model.layers.6.self_attn.k_proj.weight', 52.53125),\n",
       " ('model.layers.6.self_attn.k_proj.bias', 12.34375),\n",
       " ('model.layers.6.self_attn.v_proj.weight', 46.65625),\n",
       " ('model.layers.6.self_attn.v_proj.bias', 0.630859375),\n",
       " ('model.layers.6.self_attn.o_proj.weight', 108.875),\n",
       " ('model.layers.6.mlp.gate_proj.weight', 255.125),\n",
       " ('model.layers.6.mlp.up_proj.weight', 198.125),\n",
       " ('model.layers.6.mlp.down_proj.weight', 232.0),\n",
       " ('model.layers.6.input_layernorm.weight', 18.109375),\n",
       " ('model.layers.6.post_attention_layernorm.weight', 45.9375),\n",
       " ('model.layers.7.self_attn.q_proj.weight', 102.0625),\n",
       " ('model.layers.7.self_attn.q_proj.bias', 79.125),\n",
       " ('model.layers.7.self_attn.k_proj.weight', 54.65625),\n",
       " ('model.layers.7.self_attn.k_proj.bias', 11.2734375),\n",
       " ('model.layers.7.self_attn.v_proj.weight', 51.15625),\n",
       " ('model.layers.7.self_attn.v_proj.bias', 0.5361328125),\n",
       " ('model.layers.7.self_attn.o_proj.weight', 113.125),\n",
       " ('model.layers.7.mlp.gate_proj.weight', 280.5),\n",
       " ('model.layers.7.mlp.up_proj.weight', 228.875),\n",
       " ('model.layers.7.mlp.down_proj.weight', 247.875),\n",
       " ('model.layers.7.input_layernorm.weight', 21.734375),\n",
       " ('model.layers.7.post_attention_layernorm.weight', 51.84375),\n",
       " ('model.layers.8.self_attn.q_proj.weight', 87.8125),\n",
       " ('model.layers.8.self_attn.q_proj.bias', 89.125),\n",
       " ('model.layers.8.self_attn.k_proj.weight', 50.25),\n",
       " ('model.layers.8.self_attn.k_proj.bias', 11.96875),\n",
       " ('model.layers.8.self_attn.v_proj.weight', 49.21875),\n",
       " ('model.layers.8.self_attn.v_proj.bias', 1.265625),\n",
       " ('model.layers.8.self_attn.o_proj.weight', 106.625),\n",
       " ('model.layers.8.mlp.gate_proj.weight', 292.75),\n",
       " ('model.layers.8.mlp.up_proj.weight', 244.875),\n",
       " ('model.layers.8.mlp.down_proj.weight', 248.125),\n",
       " ('model.layers.8.input_layernorm.weight', 17.875),\n",
       " ('model.layers.8.post_attention_layernorm.weight', 33.59375),\n",
       " ('model.layers.9.self_attn.q_proj.weight', 100.0625),\n",
       " ('model.layers.9.self_attn.q_proj.bias', 77.75),\n",
       " ('model.layers.9.self_attn.k_proj.weight', 54.15625),\n",
       " ('model.layers.9.self_attn.k_proj.bias', 14.2265625),\n",
       " ('model.layers.9.self_attn.v_proj.weight', 51.96875),\n",
       " ('model.layers.9.self_attn.v_proj.bias', 0.92919921875),\n",
       " ('model.layers.9.self_attn.o_proj.weight', 111.875),\n",
       " ('model.layers.9.mlp.gate_proj.weight', 262.0),\n",
       " ('model.layers.9.mlp.up_proj.weight', 254.25),\n",
       " ('model.layers.9.mlp.down_proj.weight', 258.25),\n",
       " ('model.layers.9.input_layernorm.weight', 22.546875),\n",
       " ('model.layers.9.post_attention_layernorm.weight', 22.75),\n",
       " ('model.layers.10.self_attn.q_proj.weight', 111.4375),\n",
       " ('model.layers.10.self_attn.q_proj.bias', 78.4375),\n",
       " ('model.layers.10.self_attn.k_proj.weight', 58.6875),\n",
       " ('model.layers.10.self_attn.k_proj.bias', 13.1484375),\n",
       " ('model.layers.10.self_attn.v_proj.weight', 51.0),\n",
       " ('model.layers.10.self_attn.v_proj.bias', 0.8154296875),\n",
       " ('model.layers.10.self_attn.o_proj.weight', 112.5),\n",
       " ('model.layers.10.mlp.gate_proj.weight', 264.0),\n",
       " ('model.layers.10.mlp.up_proj.weight', 257.75),\n",
       " ('model.layers.10.mlp.down_proj.weight', 260.5),\n",
       " ('model.layers.10.input_layernorm.weight', 27.21875),\n",
       " ('model.layers.10.post_attention_layernorm.weight', 24.34375),\n",
       " ('model.layers.11.self_attn.q_proj.weight', 97.125),\n",
       " ('model.layers.11.self_attn.q_proj.bias', 78.8125),\n",
       " ('model.layers.11.self_attn.k_proj.weight', 53.90625),\n",
       " ('model.layers.11.self_attn.k_proj.bias', 17.875),\n",
       " ('model.layers.11.self_attn.v_proj.weight', 52.03125),\n",
       " ('model.layers.11.self_attn.v_proj.bias', 0.904296875),\n",
       " ('model.layers.11.self_attn.o_proj.weight', 110.75),\n",
       " ('model.layers.11.mlp.gate_proj.weight', 269.0),\n",
       " ('model.layers.11.mlp.up_proj.weight', 254.0),\n",
       " ('model.layers.11.mlp.down_proj.weight', 257.75),\n",
       " ('model.layers.11.input_layernorm.weight', 17.203125),\n",
       " ('model.layers.11.post_attention_layernorm.weight', 26.453125),\n",
       " ('model.layers.12.self_attn.q_proj.weight', 103.0625),\n",
       " ('model.layers.12.self_attn.q_proj.bias', 77.9375),\n",
       " ('model.layers.12.self_attn.k_proj.weight', 55.09375),\n",
       " ('model.layers.12.self_attn.k_proj.bias', 15.4453125),\n",
       " ('model.layers.12.self_attn.v_proj.weight', 53.15625),\n",
       " ('model.layers.12.self_attn.v_proj.bias', 1.275390625),\n",
       " ('model.layers.12.self_attn.o_proj.weight', 110.8125),\n",
       " ('model.layers.12.mlp.gate_proj.weight', 266.5),\n",
       " ('model.layers.12.mlp.up_proj.weight', 259.0),\n",
       " ('model.layers.12.mlp.down_proj.weight', 263.25),\n",
       " ('model.layers.12.input_layernorm.weight', 23.515625),\n",
       " ('model.layers.12.post_attention_layernorm.weight', 28.03125),\n",
       " ('model.layers.13.self_attn.q_proj.weight', 99.1875),\n",
       " ('model.layers.13.self_attn.q_proj.bias', 74.4375),\n",
       " ('model.layers.13.self_attn.k_proj.weight', 52.96875),\n",
       " ('model.layers.13.self_attn.k_proj.bias', 15.640625),\n",
       " ('model.layers.13.self_attn.v_proj.weight', 52.96875),\n",
       " ('model.layers.13.self_attn.v_proj.bias', 0.69140625),\n",
       " ('model.layers.13.self_attn.o_proj.weight', 110.25),\n",
       " ('model.layers.13.mlp.gate_proj.weight', 267.0),\n",
       " ('model.layers.13.mlp.up_proj.weight', 257.75),\n",
       " ('model.layers.13.mlp.down_proj.weight', 261.25),\n",
       " ('model.layers.13.input_layernorm.weight', 22.796875),\n",
       " ('model.layers.13.post_attention_layernorm.weight', 29.625),\n",
       " ('model.layers.14.self_attn.q_proj.weight', 108.75),\n",
       " ('model.layers.14.self_attn.q_proj.bias', 74.5625),\n",
       " ('model.layers.14.self_attn.k_proj.weight', 56.90625),\n",
       " ('model.layers.14.self_attn.k_proj.bias', 14.6171875),\n",
       " ('model.layers.14.self_attn.v_proj.weight', 51.40625),\n",
       " ('model.layers.14.self_attn.v_proj.bias', 0.705078125),\n",
       " ('model.layers.14.self_attn.o_proj.weight', 111.3125),\n",
       " ('model.layers.14.mlp.gate_proj.weight', 267.75),\n",
       " ('model.layers.14.mlp.up_proj.weight', 257.5),\n",
       " ('model.layers.14.mlp.down_proj.weight', 260.75),\n",
       " ('model.layers.14.input_layernorm.weight', 27.21875),\n",
       " ('model.layers.14.post_attention_layernorm.weight', 30.484375),\n",
       " ('model.layers.15.self_attn.q_proj.weight', 106.6875),\n",
       " ('model.layers.15.self_attn.q_proj.bias', 69.8125),\n",
       " ('model.layers.15.self_attn.k_proj.weight', 55.375),\n",
       " ('model.layers.15.self_attn.k_proj.bias', 16.109375),\n",
       " ('model.layers.15.self_attn.v_proj.weight', 53.9375),\n",
       " ('model.layers.15.self_attn.v_proj.bias', 0.71435546875),\n",
       " ('model.layers.15.self_attn.o_proj.weight', 114.0),\n",
       " ('model.layers.15.mlp.gate_proj.weight', 269.5),\n",
       " ('model.layers.15.mlp.up_proj.weight', 254.25),\n",
       " ('model.layers.15.mlp.down_proj.weight', 258.5),\n",
       " ('model.layers.15.input_layernorm.weight', 28.578125),\n",
       " ('model.layers.15.post_attention_layernorm.weight', 32.46875),\n",
       " ('model.layers.16.self_attn.q_proj.weight', 100.875),\n",
       " ('model.layers.16.self_attn.q_proj.bias', 74.3125),\n",
       " ('model.layers.16.self_attn.k_proj.weight', 54.21875),\n",
       " ('model.layers.16.self_attn.k_proj.bias', 17.484375),\n",
       " ('model.layers.16.self_attn.v_proj.weight', 52.6875),\n",
       " ('model.layers.16.self_attn.v_proj.bias', 0.81494140625),\n",
       " ('model.layers.16.self_attn.o_proj.weight', 109.625),\n",
       " ('model.layers.16.mlp.gate_proj.weight', 266.5),\n",
       " ('model.layers.16.mlp.up_proj.weight', 256.25),\n",
       " ('model.layers.16.mlp.down_proj.weight', 259.5),\n",
       " ('model.layers.16.input_layernorm.weight', 22.90625),\n",
       " ('model.layers.16.post_attention_layernorm.weight', 31.6875),\n",
       " ('model.layers.17.self_attn.q_proj.weight', 103.3125),\n",
       " ('model.layers.17.self_attn.q_proj.bias', 77.125),\n",
       " ('model.layers.17.self_attn.k_proj.weight', 55.6875),\n",
       " ('model.layers.17.self_attn.k_proj.bias', 14.609375),\n",
       " ('model.layers.17.self_attn.v_proj.weight', 50.375),\n",
       " ('model.layers.17.self_attn.v_proj.bias', 0.99951171875),\n",
       " ('model.layers.17.self_attn.o_proj.weight', 107.6875),\n",
       " ('model.layers.17.mlp.gate_proj.weight', 264.75),\n",
       " ('model.layers.17.mlp.up_proj.weight', 256.25),\n",
       " ('model.layers.17.mlp.down_proj.weight', 259.0),\n",
       " ('model.layers.17.input_layernorm.weight', 27.140625),\n",
       " ('model.layers.17.post_attention_layernorm.weight', 31.234375),\n",
       " ('model.layers.18.self_attn.q_proj.weight', 100.8125),\n",
       " ('model.layers.18.self_attn.q_proj.bias', 72.5),\n",
       " ('model.layers.18.self_attn.k_proj.weight', 54.5),\n",
       " ('model.layers.18.self_attn.k_proj.bias', 16.921875),\n",
       " ('model.layers.18.self_attn.v_proj.weight', 52.625),\n",
       " ('model.layers.18.self_attn.v_proj.bias', 1.291015625),\n",
       " ('model.layers.18.self_attn.o_proj.weight', 108.6875),\n",
       " ('model.layers.18.mlp.gate_proj.weight', 263.25),\n",
       " ('model.layers.18.mlp.up_proj.weight', 256.0),\n",
       " ('model.layers.18.mlp.down_proj.weight', 258.0),\n",
       " ('model.layers.18.input_layernorm.weight', 25.890625),\n",
       " ('model.layers.18.post_attention_layernorm.weight', 30.421875),\n",
       " ('model.layers.19.self_attn.q_proj.weight', 99.9375),\n",
       " ('model.layers.19.self_attn.q_proj.bias', 71.6875),\n",
       " ('model.layers.19.self_attn.k_proj.weight', 53.96875),\n",
       " ('model.layers.19.self_attn.k_proj.bias', 17.3125),\n",
       " ('model.layers.19.self_attn.v_proj.weight', 50.34375),\n",
       " ('model.layers.19.self_attn.v_proj.bias', 1.439453125),\n",
       " ('model.layers.19.self_attn.o_proj.weight', 105.4375),\n",
       " ('model.layers.19.mlp.gate_proj.weight', 261.75),\n",
       " ('model.layers.19.mlp.up_proj.weight', 255.0),\n",
       " ('model.layers.19.mlp.down_proj.weight', 256.5),\n",
       " ('model.layers.19.input_layernorm.weight', 25.1875),\n",
       " ('model.layers.19.post_attention_layernorm.weight', 30.265625),\n",
       " ('model.layers.20.self_attn.q_proj.weight', 96.1875),\n",
       " ('model.layers.20.self_attn.q_proj.bias', 71.125),\n",
       " ('model.layers.20.self_attn.k_proj.weight', 53.40625),\n",
       " ('model.layers.20.self_attn.k_proj.bias', 17.171875),\n",
       " ('model.layers.20.self_attn.v_proj.weight', 50.90625),\n",
       " ('model.layers.20.self_attn.v_proj.bias', 1.361328125),\n",
       " ('model.layers.20.self_attn.o_proj.weight', 105.3125),\n",
       " ('model.layers.20.mlp.gate_proj.weight', 260.25),\n",
       " ('model.layers.20.mlp.up_proj.weight', 255.125),\n",
       " ('model.layers.20.mlp.down_proj.weight', 256.0),\n",
       " ('model.layers.20.input_layernorm.weight', 22.671875),\n",
       " ('model.layers.20.post_attention_layernorm.weight', 28.953125),\n",
       " ('model.layers.21.self_attn.q_proj.weight', 107.25),\n",
       " ('model.layers.21.self_attn.q_proj.bias', 70.625),\n",
       " ('model.layers.21.self_attn.k_proj.weight', 57.21875),\n",
       " ('model.layers.21.self_attn.k_proj.bias', 19.140625),\n",
       " ('model.layers.21.self_attn.v_proj.weight', 49.9375),\n",
       " ('model.layers.21.self_attn.v_proj.bias', 1.73828125),\n",
       " ('model.layers.21.self_attn.o_proj.weight', 107.75),\n",
       " ('model.layers.21.mlp.gate_proj.weight', 259.0),\n",
       " ('model.layers.21.mlp.up_proj.weight', 254.0),\n",
       " ('model.layers.21.mlp.down_proj.weight', 254.875),\n",
       " ('model.layers.21.input_layernorm.weight', 26.8125),\n",
       " ('model.layers.21.post_attention_layernorm.weight', 28.703125),\n",
       " ('model.layers.22.self_attn.q_proj.weight', 106.25),\n",
       " ('model.layers.22.self_attn.q_proj.bias', 70.5625),\n",
       " ('model.layers.22.self_attn.k_proj.weight', 55.6875),\n",
       " ('model.layers.22.self_attn.k_proj.bias', 18.6875),\n",
       " ('model.layers.22.self_attn.v_proj.weight', 52.75),\n",
       " ('model.layers.22.self_attn.v_proj.bias', 0.935546875),\n",
       " ('model.layers.22.self_attn.o_proj.weight', 112.375),\n",
       " ('model.layers.22.mlp.gate_proj.weight', 259.75),\n",
       " ('model.layers.22.mlp.up_proj.weight', 254.875),\n",
       " ('model.layers.22.mlp.down_proj.weight', 256.0),\n",
       " ('model.layers.22.input_layernorm.weight', 29.453125),\n",
       " ('model.layers.22.post_attention_layernorm.weight', 29.265625),\n",
       " ('model.layers.23.self_attn.q_proj.weight', 105.9375),\n",
       " ('model.layers.23.self_attn.q_proj.bias', 67.8125),\n",
       " ('model.layers.23.self_attn.k_proj.weight', 55.78125),\n",
       " ('model.layers.23.self_attn.k_proj.bias', 30.3125),\n",
       " ('model.layers.23.self_attn.v_proj.weight', 53.4375),\n",
       " ('model.layers.23.self_attn.v_proj.bias', 0.904296875),\n",
       " ('model.layers.23.self_attn.o_proj.weight', 113.0),\n",
       " ('model.layers.23.mlp.gate_proj.weight', 261.75),\n",
       " ('model.layers.23.mlp.up_proj.weight', 255.25),\n",
       " ('model.layers.23.mlp.down_proj.weight', 257.25),\n",
       " ('model.layers.23.input_layernorm.weight', 30.671875),\n",
       " ('model.layers.23.post_attention_layernorm.weight', 30.046875),\n",
       " ('model.layers.24.self_attn.q_proj.weight', 102.0625),\n",
       " ('model.layers.24.self_attn.q_proj.bias', 70.875),\n",
       " ('model.layers.24.self_attn.k_proj.weight', 54.71875),\n",
       " ('model.layers.24.self_attn.k_proj.bias', 17.046875),\n",
       " ('model.layers.24.self_attn.v_proj.weight', 51.65625),\n",
       " ('model.layers.24.self_attn.v_proj.bias', 0.97509765625),\n",
       " ('model.layers.24.self_attn.o_proj.weight', 107.6875),\n",
       " ('model.layers.24.mlp.gate_proj.weight', 261.75),\n",
       " ('model.layers.24.mlp.up_proj.weight', 256.0),\n",
       " ('model.layers.24.mlp.down_proj.weight', 257.75),\n",
       " ('model.layers.24.input_layernorm.weight', 30.90625),\n",
       " ('model.layers.24.post_attention_layernorm.weight', 30.34375),\n",
       " ('model.layers.25.self_attn.q_proj.weight', 103.1875),\n",
       " ('model.layers.25.self_attn.q_proj.bias', 67.25),\n",
       " ('model.layers.25.self_attn.k_proj.weight', 54.9375),\n",
       " ('model.layers.25.self_attn.k_proj.bias', 20.328125),\n",
       " ('model.layers.25.self_attn.v_proj.weight', 49.0625),\n",
       " ('model.layers.25.self_attn.v_proj.bias', 1.08203125),\n",
       " ('model.layers.25.self_attn.o_proj.weight', 105.375),\n",
       " ('model.layers.25.mlp.gate_proj.weight', 261.75),\n",
       " ('model.layers.25.mlp.up_proj.weight', 257.5),\n",
       " ('model.layers.25.mlp.down_proj.weight', 257.5),\n",
       " ('model.layers.25.input_layernorm.weight', 34.65625),\n",
       " ('model.layers.25.post_attention_layernorm.weight', 29.4375),\n",
       " ('model.layers.26.self_attn.q_proj.weight', 111.3125),\n",
       " ('model.layers.26.self_attn.q_proj.bias', 66.375),\n",
       " ('model.layers.26.self_attn.k_proj.weight', 59.53125),\n",
       " ('model.layers.26.self_attn.k_proj.bias', 22.703125),\n",
       " ('model.layers.26.self_attn.v_proj.weight', 48.71875),\n",
       " ('model.layers.26.self_attn.v_proj.bias', 2.068359375),\n",
       " ('model.layers.26.self_attn.o_proj.weight', 106.375),\n",
       " ('model.layers.26.mlp.gate_proj.weight', 260.75),\n",
       " ('model.layers.26.mlp.up_proj.weight', 257.5),\n",
       " ('model.layers.26.mlp.down_proj.weight', 256.5),\n",
       " ('model.layers.26.input_layernorm.weight', 30.5),\n",
       " ('model.layers.26.post_attention_layernorm.weight', 28.5625),\n",
       " ('model.layers.27.self_attn.q_proj.weight', 111.75),\n",
       " ('model.layers.27.self_attn.q_proj.bias', 71.75),\n",
       " ('model.layers.27.self_attn.k_proj.weight', 60.34375),\n",
       " ('model.layers.27.self_attn.k_proj.bias', 29.5),\n",
       " ('model.layers.27.self_attn.v_proj.weight', 51.75),\n",
       " ('model.layers.27.self_attn.v_proj.bias', 2.30859375),\n",
       " ('model.layers.27.self_attn.o_proj.weight', 110.6875),\n",
       " ('model.layers.27.mlp.gate_proj.weight', 260.5),\n",
       " ('model.layers.27.mlp.up_proj.weight', 257.5),\n",
       " ('model.layers.27.mlp.down_proj.weight', 256.75),\n",
       " ('model.layers.27.input_layernorm.weight', 25.84375),\n",
       " ('model.layers.27.post_attention_layernorm.weight', 28.109375),\n",
       " ('model.layers.28.self_attn.q_proj.weight', 105.375),\n",
       " ('model.layers.28.self_attn.q_proj.bias', 69.0625),\n",
       " ('model.layers.28.self_attn.k_proj.weight', 55.9375),\n",
       " ('model.layers.28.self_attn.k_proj.bias', 27.21875),\n",
       " ('model.layers.28.self_attn.v_proj.weight', 54.09375),\n",
       " ('model.layers.28.self_attn.v_proj.bias', 1.2314453125),\n",
       " ('model.layers.28.self_attn.o_proj.weight', 111.4375),\n",
       " ('model.layers.28.mlp.gate_proj.weight', 261.75),\n",
       " ('model.layers.28.mlp.up_proj.weight', 258.75),\n",
       " ('model.layers.28.mlp.down_proj.weight', 258.75),\n",
       " ('model.layers.28.input_layernorm.weight', 29.984375),\n",
       " ('model.layers.28.post_attention_layernorm.weight', 28.296875),\n",
       " ('model.layers.29.self_attn.q_proj.weight', 110.75),\n",
       " ('model.layers.29.self_attn.q_proj.bias', 65.125),\n",
       " ('model.layers.29.self_attn.k_proj.weight', 54.71875),\n",
       " ('model.layers.29.self_attn.k_proj.bias', 23.6875),\n",
       " ('model.layers.29.self_attn.v_proj.weight', 56.3125),\n",
       " ('model.layers.29.self_attn.v_proj.bias', 1.23046875),\n",
       " ('model.layers.29.self_attn.o_proj.weight', 114.875),\n",
       " ('model.layers.29.mlp.gate_proj.weight', 263.5),\n",
       " ('model.layers.29.mlp.up_proj.weight', 260.5),\n",
       " ('model.layers.29.mlp.down_proj.weight', 260.5),\n",
       " ('model.layers.29.input_layernorm.weight', 31.8125),\n",
       " ('model.layers.29.post_attention_layernorm.weight', 29.578125),\n",
       " ('model.layers.30.self_attn.q_proj.weight', 114.3125),\n",
       " ('model.layers.30.self_attn.q_proj.bias', 64.9375),\n",
       " ('model.layers.30.self_attn.k_proj.weight', 56.46875),\n",
       " ('model.layers.30.self_attn.k_proj.bias', 25.953125),\n",
       " ('model.layers.30.self_attn.v_proj.weight', 55.96875),\n",
       " ('model.layers.30.self_attn.v_proj.bias', 1.564453125),\n",
       " ('model.layers.30.self_attn.o_proj.weight', 117.4375),\n",
       " ('model.layers.30.mlp.gate_proj.weight', 265.25),\n",
       " ('model.layers.30.mlp.up_proj.weight', 261.5),\n",
       " ('model.layers.30.mlp.down_proj.weight', 262.0),\n",
       " ('model.layers.30.input_layernorm.weight', 32.3125),\n",
       " ('model.layers.30.post_attention_layernorm.weight', 30.640625),\n",
       " ('model.layers.31.self_attn.q_proj.weight', 114.0625),\n",
       " ('model.layers.31.self_attn.q_proj.bias', 66.8125),\n",
       " ('model.layers.31.self_attn.k_proj.weight', 56.1875),\n",
       " ('model.layers.31.self_attn.k_proj.bias', 24.8125),\n",
       " ('model.layers.31.self_attn.v_proj.weight', 56.84375),\n",
       " ('model.layers.31.self_attn.v_proj.bias', 1.34765625),\n",
       " ('model.layers.31.self_attn.o_proj.weight', 118.8125),\n",
       " ('model.layers.31.mlp.gate_proj.weight', 267.75),\n",
       " ('model.layers.31.mlp.up_proj.weight', 262.5),\n",
       " ('model.layers.31.mlp.down_proj.weight', 263.25),\n",
       " ('model.layers.31.input_layernorm.weight', 33.5),\n",
       " ('model.layers.31.post_attention_layernorm.weight', 32.15625),\n",
       " ('model.layers.32.self_attn.q_proj.weight', 112.8125),\n",
       " ('model.layers.32.self_attn.q_proj.bias', 73.75),\n",
       " ('model.layers.32.self_attn.k_proj.weight', 55.8125),\n",
       " ('model.layers.32.self_attn.k_proj.bias', 27.21875),\n",
       " ('model.layers.32.self_attn.v_proj.weight', 56.40625),\n",
       " ('model.layers.32.self_attn.v_proj.bias', 2.60546875),\n",
       " ('model.layers.32.self_attn.o_proj.weight', 115.5),\n",
       " ('model.layers.32.mlp.gate_proj.weight', 278.25),\n",
       " ('model.layers.32.mlp.up_proj.weight', 261.5),\n",
       " ('model.layers.32.mlp.down_proj.weight', 263.5),\n",
       " ('model.layers.32.input_layernorm.weight', 25.234375),\n",
       " ('model.layers.32.post_attention_layernorm.weight', 36.90625),\n",
       " ('model.layers.33.self_attn.q_proj.weight', 115.625),\n",
       " ('model.layers.33.self_attn.q_proj.bias', 77.5),\n",
       " ('model.layers.33.self_attn.k_proj.weight', 58.1875),\n",
       " ('model.layers.33.self_attn.k_proj.bias', 16.703125),\n",
       " ('model.layers.33.self_attn.v_proj.weight', 53.4375),\n",
       " ('model.layers.33.self_attn.v_proj.bias', 1.84375),\n",
       " ('model.layers.33.self_attn.o_proj.weight', 113.8125),\n",
       " ('model.layers.33.mlp.gate_proj.weight', 276.0),\n",
       " ('model.layers.33.mlp.up_proj.weight', 265.0),\n",
       " ('model.layers.33.mlp.down_proj.weight', 266.0),\n",
       " ('model.layers.33.input_layernorm.weight', 30.90625),\n",
       " ('model.layers.33.post_attention_layernorm.weight', 36.59375),\n",
       " ('model.layers.34.self_attn.q_proj.weight', 113.9375),\n",
       " ('model.layers.34.self_attn.q_proj.bias', 72.0625),\n",
       " ('model.layers.34.self_attn.k_proj.weight', 57.28125),\n",
       " ('model.layers.34.self_attn.k_proj.bias', 19.75),\n",
       " ('model.layers.34.self_attn.v_proj.weight', 56.65625),\n",
       " ('model.layers.34.self_attn.v_proj.bias', 2.732421875),\n",
       " ('model.layers.34.self_attn.o_proj.weight', 115.8125),\n",
       " ('model.layers.34.mlp.gate_proj.weight', 274.75),\n",
       " ('model.layers.34.mlp.up_proj.weight', 268.5),\n",
       " ('model.layers.34.mlp.down_proj.weight', 268.5),\n",
       " ('model.layers.34.input_layernorm.weight', 30.671875),\n",
       " ('model.layers.34.post_attention_layernorm.weight', 36.3125),\n",
       " ('model.layers.35.self_attn.q_proj.weight', 111.4375),\n",
       " ('model.layers.35.self_attn.q_proj.bias', 71.3125),\n",
       " ('model.layers.35.self_attn.k_proj.weight', 54.96875),\n",
       " ('model.layers.35.self_attn.k_proj.bias', 18.296875),\n",
       " ('model.layers.35.self_attn.v_proj.weight', 55.09375),\n",
       " ('model.layers.35.self_attn.v_proj.bias', 2.94921875),\n",
       " ('model.layers.35.self_attn.o_proj.weight', 113.9375),\n",
       " ('model.layers.35.mlp.gate_proj.weight', 274.25),\n",
       " ('model.layers.35.mlp.up_proj.weight', 270.5),\n",
       " ('model.layers.35.mlp.down_proj.weight', 269.5),\n",
       " ('model.layers.35.input_layernorm.weight', 32.15625),\n",
       " ('model.layers.35.post_attention_layernorm.weight', 37.3125),\n",
       " ('model.layers.36.self_attn.q_proj.weight', 112.625),\n",
       " ('model.layers.36.self_attn.q_proj.bias', 69.875),\n",
       " ('model.layers.36.self_attn.k_proj.weight', 55.125),\n",
       " ('model.layers.36.self_attn.k_proj.bias', 19.03125),\n",
       " ('model.layers.36.self_attn.v_proj.weight', 56.90625),\n",
       " ('model.layers.36.self_attn.v_proj.bias', 3.2890625),\n",
       " ('model.layers.36.self_attn.o_proj.weight', 115.75),\n",
       " ('model.layers.36.mlp.gate_proj.weight', 270.5),\n",
       " ('model.layers.36.mlp.up_proj.weight', 274.5),\n",
       " ('model.layers.36.mlp.down_proj.weight', 272.0),\n",
       " ('model.layers.36.input_layernorm.weight', 31.90625),\n",
       " ('model.layers.36.post_attention_layernorm.weight', 36.875),\n",
       " ('model.layers.37.self_attn.q_proj.weight', 116.75),\n",
       " ('model.layers.37.self_attn.q_proj.bias', 70.5),\n",
       " ('model.layers.37.self_attn.k_proj.weight', 57.6875),\n",
       " ('model.layers.37.self_attn.k_proj.bias', 26.734375),\n",
       " ('model.layers.37.self_attn.v_proj.weight', 56.5),\n",
       " ('model.layers.37.self_attn.v_proj.bias', 2.611328125),\n",
       " ('model.layers.37.self_attn.o_proj.weight', 116.25),\n",
       " ('model.layers.37.mlp.gate_proj.weight', 268.5),\n",
       " ('model.layers.37.mlp.up_proj.weight', 275.25),\n",
       " ('model.layers.37.mlp.down_proj.weight', 272.25),\n",
       " ('model.layers.37.input_layernorm.weight', 36.09375),\n",
       " ('model.layers.37.post_attention_layernorm.weight', 38.125),\n",
       " ('model.layers.38.self_attn.q_proj.weight', 113.6875),\n",
       " ('model.layers.38.self_attn.q_proj.bias', 68.875),\n",
       " ('model.layers.38.self_attn.k_proj.weight', 53.625),\n",
       " ('model.layers.38.self_attn.k_proj.bias', 24.046875),\n",
       " ('model.layers.38.self_attn.v_proj.weight', 60.5625),\n",
       " ('model.layers.38.self_attn.v_proj.bias', 2.013671875),\n",
       " ('model.layers.38.self_attn.o_proj.weight', 121.3125),\n",
       " ('model.layers.38.mlp.gate_proj.weight', 266.0),\n",
       " ('model.layers.38.mlp.up_proj.weight', 277.0),\n",
       " ('model.layers.38.mlp.down_proj.weight', 274.25),\n",
       " ('model.layers.38.input_layernorm.weight', 39.65625),\n",
       " ('model.layers.38.post_attention_layernorm.weight', 39.9375),\n",
       " ('model.layers.39.self_attn.q_proj.weight', 111.8125),\n",
       " ('model.layers.39.self_attn.q_proj.bias', 66.3125),\n",
       " ('model.layers.39.self_attn.k_proj.weight', 53.0),\n",
       " ('model.layers.39.self_attn.k_proj.bias', 39.46875),\n",
       " ('model.layers.39.self_attn.v_proj.weight', 61.6875),\n",
       " ('model.layers.39.self_attn.v_proj.bias', 2.154296875),\n",
       " ('model.layers.39.self_attn.o_proj.weight', 122.9375),\n",
       " ('model.layers.39.mlp.gate_proj.weight', 266.0),\n",
       " ('model.layers.39.mlp.up_proj.weight', 278.5),\n",
       " ('model.layers.39.mlp.down_proj.weight', 276.5),\n",
       " ('model.layers.39.input_layernorm.weight', 43.5),\n",
       " ('model.layers.39.post_attention_layernorm.weight', 41.40625),\n",
       " ('model.layers.40.self_attn.q_proj.weight', 114.0625),\n",
       " ('model.layers.40.self_attn.q_proj.bias', 70.25),\n",
       " ('model.layers.40.self_attn.k_proj.weight', 53.59375),\n",
       " ('model.layers.40.self_attn.k_proj.bias', 33.71875),\n",
       " ('model.layers.40.self_attn.v_proj.weight', 60.34375),\n",
       " ('model.layers.40.self_attn.v_proj.bias', 2.53125),\n",
       " ('model.layers.40.self_attn.o_proj.weight', 119.5),\n",
       " ('model.layers.40.mlp.gate_proj.weight', 265.25),\n",
       " ('model.layers.40.mlp.up_proj.weight', 279.25),\n",
       " ('model.layers.40.mlp.down_proj.weight', 276.5),\n",
       " ('model.layers.40.input_layernorm.weight', 41.71875),\n",
       " ('model.layers.40.post_attention_layernorm.weight', 43.09375),\n",
       " ('model.layers.41.self_attn.q_proj.weight', 109.375),\n",
       " ('model.layers.41.self_attn.q_proj.bias', 64.4375),\n",
       " ('model.layers.41.self_attn.k_proj.weight', 51.1875),\n",
       " ('model.layers.41.self_attn.k_proj.bias', 40.0),\n",
       " ('model.layers.41.self_attn.v_proj.weight', 59.53125),\n",
       " ('model.layers.41.self_attn.v_proj.bias', 1.685546875),\n",
       " ('model.layers.41.self_attn.o_proj.weight', 119.8125),\n",
       " ('model.layers.41.mlp.gate_proj.weight', 260.25),\n",
       " ('model.layers.41.mlp.up_proj.weight', 280.75),\n",
       " ('model.layers.41.mlp.down_proj.weight', 276.5),\n",
       " ('model.layers.41.input_layernorm.weight', 47.25),\n",
       " ('model.layers.41.post_attention_layernorm.weight', 43.71875),\n",
       " ('model.layers.42.self_attn.q_proj.weight', 113.6875),\n",
       " ('model.layers.42.self_attn.q_proj.bias', 66.5625),\n",
       " ('model.layers.42.self_attn.k_proj.weight', 56.09375),\n",
       " ('model.layers.42.self_attn.k_proj.bias', 37.65625),\n",
       " ('model.layers.42.self_attn.v_proj.weight', 57.46875),\n",
       " ('model.layers.42.self_attn.v_proj.bias', 1.791015625),\n",
       " ('model.layers.42.self_attn.o_proj.weight', 117.1875),\n",
       " ('model.layers.42.mlp.gate_proj.weight', 254.5),\n",
       " ('model.layers.42.mlp.up_proj.weight', 281.75),\n",
       " ('model.layers.42.mlp.down_proj.weight', 277.25),\n",
       " ('model.layers.42.input_layernorm.weight', 46.03125),\n",
       " ('model.layers.42.post_attention_layernorm.weight', 44.5625),\n",
       " ('model.layers.43.self_attn.q_proj.weight', 111.5625),\n",
       " ('model.layers.43.self_attn.q_proj.bias', 74.3125),\n",
       " ('model.layers.43.self_attn.k_proj.weight', 54.65625),\n",
       " ('model.layers.43.self_attn.k_proj.bias', 50.28125),\n",
       " ('model.layers.43.self_attn.v_proj.weight', 60.625),\n",
       " ('model.layers.43.self_attn.v_proj.bias', 2.173828125),\n",
       " ('model.layers.43.self_attn.o_proj.weight', 119.375),\n",
       " ('model.layers.43.mlp.gate_proj.weight', 251.375),\n",
       " ('model.layers.43.mlp.up_proj.weight', 280.0),\n",
       " ('model.layers.43.mlp.down_proj.weight', 276.25),\n",
       " ('model.layers.43.input_layernorm.weight', 48.625),\n",
       " ('model.layers.43.post_attention_layernorm.weight', 45.8125),\n",
       " ('model.layers.44.self_attn.q_proj.weight', 104.0),\n",
       " ('model.layers.44.self_attn.q_proj.bias', 72.3125),\n",
       " ('model.layers.44.self_attn.k_proj.weight', 46.96875),\n",
       " ('model.layers.44.self_attn.k_proj.bias', 51.5625),\n",
       " ('model.layers.44.self_attn.v_proj.weight', 67.3125),\n",
       " ('model.layers.44.self_attn.v_proj.bias', 1.59375),\n",
       " ('model.layers.44.self_attn.o_proj.weight', 127.8125),\n",
       " ('model.layers.44.mlp.gate_proj.weight', 253.125),\n",
       " ('model.layers.44.mlp.up_proj.weight', 281.75),\n",
       " ('model.layers.44.mlp.down_proj.weight', 278.5),\n",
       " ('model.layers.44.input_layernorm.weight', 52.3125),\n",
       " ('model.layers.44.post_attention_layernorm.weight', 45.71875),\n",
       " ('model.layers.45.self_attn.q_proj.weight', 105.1875),\n",
       " ('model.layers.45.self_attn.q_proj.bias', 67.25),\n",
       " ('model.layers.45.self_attn.k_proj.weight', 46.5625),\n",
       " ('model.layers.45.self_attn.k_proj.bias', 51.15625),\n",
       " ('model.layers.45.self_attn.v_proj.weight', 65.1875),\n",
       " ('model.layers.45.self_attn.v_proj.bias', 1.8642578125),\n",
       " ('model.layers.45.self_attn.o_proj.weight', 126.5625),\n",
       " ('model.layers.45.mlp.gate_proj.weight', 254.5),\n",
       " ('model.layers.45.mlp.up_proj.weight', 280.5),\n",
       " ('model.layers.45.mlp.down_proj.weight', 278.0),\n",
       " ('model.layers.45.input_layernorm.weight', 51.28125),\n",
       " ('model.layers.45.post_attention_layernorm.weight', 46.78125),\n",
       " ('model.layers.46.self_attn.q_proj.weight', 106.9375),\n",
       " ('model.layers.46.self_attn.q_proj.bias', 70.3125),\n",
       " ('model.layers.46.self_attn.k_proj.weight', 48.0),\n",
       " ('model.layers.46.self_attn.k_proj.bias', 55.71875),\n",
       " ('model.layers.46.self_attn.v_proj.weight', 65.875),\n",
       " ('model.layers.46.self_attn.v_proj.bias', 1.671875),\n",
       " ('model.layers.46.self_attn.o_proj.weight', 126.9375),\n",
       " ('model.layers.46.mlp.gate_proj.weight', 257.0),\n",
       " ('model.layers.46.mlp.up_proj.weight', 279.0),\n",
       " ('model.layers.46.mlp.down_proj.weight', 277.5),\n",
       " ('model.layers.46.input_layernorm.weight', 51.6875),\n",
       " ('model.layers.46.post_attention_layernorm.weight', 47.4375),\n",
       " ('model.layers.47.self_attn.q_proj.weight', 107.75),\n",
       " ('model.layers.47.self_attn.q_proj.bias', 71.625),\n",
       " ('model.layers.47.self_attn.k_proj.weight', 49.375),\n",
       " ('model.layers.47.self_attn.k_proj.bias', 51.4375),\n",
       " ('model.layers.47.self_attn.v_proj.weight', 65.0),\n",
       " ('model.layers.47.self_attn.v_proj.bias', 1.4521484375),\n",
       " ('model.layers.47.self_attn.o_proj.weight', 125.4375),\n",
       " ('model.layers.47.mlp.gate_proj.weight', 260.25),\n",
       " ('model.layers.47.mlp.up_proj.weight', 278.75),\n",
       " ('model.layers.47.mlp.down_proj.weight', 278.25),\n",
       " ('model.layers.47.input_layernorm.weight', 50.0),\n",
       " ('model.layers.47.post_attention_layernorm.weight', 49.28125),\n",
       " ('model.layers.48.self_attn.q_proj.weight', 108.9375),\n",
       " ('model.layers.48.self_attn.q_proj.bias', 69.875),\n",
       " ('model.layers.48.self_attn.k_proj.weight', 48.0625),\n",
       " ('model.layers.48.self_attn.k_proj.bias', 38.90625),\n",
       " ('model.layers.48.self_attn.v_proj.weight', 64.375),\n",
       " ('model.layers.48.self_attn.v_proj.bias', 1.87890625),\n",
       " ('model.layers.48.self_attn.o_proj.weight', 127.1875),\n",
       " ('model.layers.48.mlp.gate_proj.weight', 264.25),\n",
       " ('model.layers.48.mlp.up_proj.weight', 277.75),\n",
       " ('model.layers.48.mlp.down_proj.weight', 277.0),\n",
       " ('model.layers.48.input_layernorm.weight', 47.53125),\n",
       " ('model.layers.48.post_attention_layernorm.weight', 50.125),\n",
       " ('model.layers.49.self_attn.q_proj.weight', 107.0),\n",
       " ('model.layers.49.self_attn.q_proj.bias', 68.3125),\n",
       " ('model.layers.49.self_attn.k_proj.weight', 47.5625),\n",
       " ('model.layers.49.self_attn.k_proj.bias', 44.59375),\n",
       " ('model.layers.49.self_attn.v_proj.weight', 66.375),\n",
       " ('model.layers.49.self_attn.v_proj.bias', 1.7744140625),\n",
       " ('model.layers.49.self_attn.o_proj.weight', 126.5625),\n",
       " ('model.layers.49.mlp.gate_proj.weight', 266.25),\n",
       " ('model.layers.49.mlp.up_proj.weight', 278.5),\n",
       " ('model.layers.49.mlp.down_proj.weight', 278.5),\n",
       " ('model.layers.49.input_layernorm.weight', 49.0625),\n",
       " ('model.layers.49.post_attention_layernorm.weight', 51.625),\n",
       " ('model.layers.50.self_attn.q_proj.weight', 104.6875),\n",
       " ('model.layers.50.self_attn.q_proj.bias', 61.625),\n",
       " ('model.layers.50.self_attn.k_proj.weight', 45.34375),\n",
       " ('model.layers.50.self_attn.k_proj.bias', 35.8125),\n",
       " ('model.layers.50.self_attn.v_proj.weight', 64.1875),\n",
       " ('model.layers.50.self_attn.v_proj.bias', 2.291015625),\n",
       " ('model.layers.50.self_attn.o_proj.weight', 125.6875),\n",
       " ('model.layers.50.mlp.gate_proj.weight', 270.0),\n",
       " ('model.layers.50.mlp.up_proj.weight', 277.25),\n",
       " ('model.layers.50.mlp.down_proj.weight', 278.5),\n",
       " ('model.layers.50.input_layernorm.weight', 49.3125),\n",
       " ('model.layers.50.post_attention_layernorm.weight', 54.5),\n",
       " ('model.layers.51.self_attn.q_proj.weight', 109.3125),\n",
       " ('model.layers.51.self_attn.q_proj.bias', 66.5625),\n",
       " ('model.layers.51.self_attn.k_proj.weight', 50.03125),\n",
       " ('model.layers.51.self_attn.k_proj.bias', 37.6875),\n",
       " ('model.layers.51.self_attn.v_proj.weight', 64.9375),\n",
       " ('model.layers.51.self_attn.v_proj.bias', 3.33203125),\n",
       " ('model.layers.51.self_attn.o_proj.weight', 125.5625),\n",
       " ('model.layers.51.mlp.gate_proj.weight', 274.0),\n",
       " ('model.layers.51.mlp.up_proj.weight', 276.75),\n",
       " ('model.layers.51.mlp.down_proj.weight', 278.5),\n",
       " ('model.layers.51.input_layernorm.weight', 43.34375),\n",
       " ('model.layers.51.post_attention_layernorm.weight', 56.78125),\n",
       " ('model.layers.52.self_attn.q_proj.weight', 103.625),\n",
       " ('model.layers.52.self_attn.q_proj.bias', 63.40625),\n",
       " ('model.layers.52.self_attn.k_proj.weight', 43.65625),\n",
       " ('model.layers.52.self_attn.k_proj.bias', 46.0625),\n",
       " ('model.layers.52.self_attn.v_proj.weight', 68.8125),\n",
       " ('model.layers.52.self_attn.v_proj.bias', 2.392578125),\n",
       " ('model.layers.52.self_attn.o_proj.weight', 131.375),\n",
       " ('model.layers.52.mlp.gate_proj.weight', 275.25),\n",
       " ('model.layers.52.mlp.up_proj.weight', 277.5),\n",
       " ('model.layers.52.mlp.down_proj.weight', 279.25),\n",
       " ('model.layers.52.input_layernorm.weight', 48.5625),\n",
       " ('model.layers.52.post_attention_layernorm.weight', 57.6875),\n",
       " ('model.layers.53.self_attn.q_proj.weight', 107.0),\n",
       " ('model.layers.53.self_attn.q_proj.bias', 69.0625),\n",
       " ('model.layers.53.self_attn.k_proj.weight', 46.59375),\n",
       " ('model.layers.53.self_attn.k_proj.bias', 32.40625),\n",
       " ('model.layers.53.self_attn.v_proj.weight', 63.75),\n",
       " ('model.layers.53.self_attn.v_proj.bias', 3.181640625),\n",
       " ('model.layers.53.self_attn.o_proj.weight', 126.6875),\n",
       " ('model.layers.53.mlp.gate_proj.weight', 277.5),\n",
       " ('model.layers.53.mlp.up_proj.weight', 277.75),\n",
       " ('model.layers.53.mlp.down_proj.weight', 279.5),\n",
       " ('model.layers.53.input_layernorm.weight', 45.6875),\n",
       " ('model.layers.53.post_attention_layernorm.weight', 59.5625),\n",
       " ('model.layers.54.self_attn.q_proj.weight', 106.5),\n",
       " ('model.layers.54.self_attn.q_proj.bias', 68.375),\n",
       " ('model.layers.54.self_attn.k_proj.weight', 46.40625),\n",
       " ('model.layers.54.self_attn.k_proj.bias', 39.125),\n",
       " ('model.layers.54.self_attn.v_proj.weight', 65.75),\n",
       " ('model.layers.54.self_attn.v_proj.bias', 2.974609375),\n",
       " ('model.layers.54.self_attn.o_proj.weight', 124.9375),\n",
       " ('model.layers.54.mlp.gate_proj.weight', 278.25),\n",
       " ('model.layers.54.mlp.up_proj.weight', 279.25),\n",
       " ('model.layers.54.mlp.down_proj.weight', 279.75),\n",
       " ('model.layers.54.input_layernorm.weight', 47.03125),\n",
       " ('model.layers.54.post_attention_layernorm.weight', 61.96875),\n",
       " ('model.layers.55.self_attn.q_proj.weight', 104.0625),\n",
       " ('model.layers.55.self_attn.q_proj.bias', 69.375),\n",
       " ('model.layers.55.self_attn.k_proj.weight', 46.3125),\n",
       " ('model.layers.55.self_attn.k_proj.bias', 36.03125),\n",
       " ('model.layers.55.self_attn.v_proj.weight', 69.5625),\n",
       " ('model.layers.55.self_attn.v_proj.bias', 3.22265625),\n",
       " ('model.layers.55.self_attn.o_proj.weight', 126.375),\n",
       " ('model.layers.55.mlp.gate_proj.weight', 278.5),\n",
       " ('model.layers.55.mlp.up_proj.weight', 280.5),\n",
       " ('model.layers.55.mlp.down_proj.weight', 280.25),\n",
       " ('model.layers.55.input_layernorm.weight', 47.53125),\n",
       " ('model.layers.55.post_attention_layernorm.weight', 63.375),\n",
       " ('model.layers.56.self_attn.q_proj.weight', 100.375),\n",
       " ('model.layers.56.self_attn.q_proj.bias', 71.5),\n",
       " ('model.layers.56.self_attn.k_proj.weight', 42.28125),\n",
       " ('model.layers.56.self_attn.k_proj.bias', 26.59375),\n",
       " ('model.layers.56.self_attn.v_proj.weight', 68.75),\n",
       " ('model.layers.56.self_attn.v_proj.bias', 3.7109375),\n",
       " ('model.layers.56.self_attn.o_proj.weight', 126.5),\n",
       " ('model.layers.56.mlp.gate_proj.weight', 278.0),\n",
       " ('model.layers.56.mlp.up_proj.weight', 281.25),\n",
       " ('model.layers.56.mlp.down_proj.weight', 280.75),\n",
       " ('model.layers.56.input_layernorm.weight', 47.53125),\n",
       " ('model.layers.56.post_attention_layernorm.weight', 65.125),\n",
       " ('model.layers.57.self_attn.q_proj.weight', 100.5625),\n",
       " ('model.layers.57.self_attn.q_proj.bias', 72.8125),\n",
       " ('model.layers.57.self_attn.k_proj.weight', 42.6875),\n",
       " ('model.layers.57.self_attn.k_proj.bias', 33.78125),\n",
       " ('model.layers.57.self_attn.v_proj.weight', 71.1875),\n",
       " ('model.layers.57.self_attn.v_proj.bias', 4.0078125),\n",
       " ('model.layers.57.self_attn.o_proj.weight', 128.0),\n",
       " ('model.layers.57.mlp.gate_proj.weight', 277.5),\n",
       " ('model.layers.57.mlp.up_proj.weight', 282.5),\n",
       " ('model.layers.57.mlp.down_proj.weight', 281.0),\n",
       " ('model.layers.57.input_layernorm.weight', 51.84375),\n",
       " ('model.layers.57.post_attention_layernorm.weight', 67.125),\n",
       " ('model.layers.58.self_attn.q_proj.weight', 103.8125),\n",
       " ('model.layers.58.self_attn.q_proj.bias', 69.375),\n",
       " ('model.layers.58.self_attn.k_proj.weight', 43.03125),\n",
       " ('model.layers.58.self_attn.k_proj.bias', 30.328125),\n",
       " ('model.layers.58.self_attn.v_proj.weight', 67.75),\n",
       " ('model.layers.58.self_attn.v_proj.bias', 5.01953125),\n",
       " ('model.layers.58.self_attn.o_proj.weight', 125.1875),\n",
       " ('model.layers.58.mlp.gate_proj.weight', 276.25),\n",
       " ('model.layers.58.mlp.up_proj.weight', 284.0),\n",
       " ('model.layers.58.mlp.down_proj.weight', 281.75),\n",
       " ('model.layers.58.input_layernorm.weight', 45.9375),\n",
       " ('model.layers.58.post_attention_layernorm.weight', 69.25),\n",
       " ('model.layers.59.self_attn.q_proj.weight', 96.125),\n",
       " ('model.layers.59.self_attn.q_proj.bias', 69.875),\n",
       " ('model.layers.59.self_attn.k_proj.weight', 40.65625),\n",
       " ('model.layers.59.self_attn.k_proj.bias', 25.125),\n",
       " ('model.layers.59.self_attn.v_proj.weight', 79.0),\n",
       " ('model.layers.59.self_attn.v_proj.bias', 5.58203125),\n",
       " ('model.layers.59.self_attn.o_proj.weight', 134.125),\n",
       " ('model.layers.59.mlp.gate_proj.weight', 273.5),\n",
       " ('model.layers.59.mlp.up_proj.weight', 284.25),\n",
       " ('model.layers.59.mlp.down_proj.weight', 282.0),\n",
       " ('model.layers.59.input_layernorm.weight', 50.03125),\n",
       " ('model.layers.59.post_attention_layernorm.weight', 72.5625),\n",
       " ('model.layers.60.self_attn.q_proj.weight', 92.875),\n",
       " ('model.layers.60.self_attn.q_proj.bias', 67.1875),\n",
       " ('model.layers.60.self_attn.k_proj.weight', 34.46875),\n",
       " ('model.layers.60.self_attn.k_proj.bias', 27.09375),\n",
       " ('model.layers.60.self_attn.v_proj.weight', 82.75),\n",
       " ('model.layers.60.self_attn.v_proj.bias', 5.75390625),\n",
       " ('model.layers.60.self_attn.o_proj.weight', 139.125),\n",
       " ('model.layers.60.mlp.gate_proj.weight', 270.75),\n",
       " ('model.layers.60.mlp.up_proj.weight', 285.0),\n",
       " ('model.layers.60.mlp.down_proj.weight', 282.5),\n",
       " ('model.layers.60.input_layernorm.weight', 52.59375),\n",
       " ('model.layers.60.post_attention_layernorm.weight', 76.875),\n",
       " ('model.layers.61.self_attn.q_proj.weight', 90.625),\n",
       " ('model.layers.61.self_attn.q_proj.bias', 63.5625),\n",
       " ('model.layers.61.self_attn.k_proj.weight', 33.28125),\n",
       " ('model.layers.61.self_attn.k_proj.bias', 22.078125),\n",
       " ('model.layers.61.self_attn.v_proj.weight', 84.4375),\n",
       " ('model.layers.61.self_attn.v_proj.bias', 10.765625),\n",
       " ('model.layers.61.self_attn.o_proj.weight', 138.5),\n",
       " ('model.layers.61.mlp.gate_proj.weight', 269.5),\n",
       " ('model.layers.61.mlp.up_proj.weight', 284.0),\n",
       " ('model.layers.61.mlp.down_proj.weight', 280.75),\n",
       " ('model.layers.61.input_layernorm.weight', 57.375),\n",
       " ('model.layers.61.post_attention_layernorm.weight', 82.9375),\n",
       " ('model.layers.62.self_attn.q_proj.weight', 92.3125),\n",
       " ('model.layers.62.self_attn.q_proj.bias', 56.125),\n",
       " ('model.layers.62.self_attn.k_proj.weight', 34.625),\n",
       " ('model.layers.62.self_attn.k_proj.bias', 22.765625),\n",
       " ('model.layers.62.self_attn.v_proj.weight', 92.5),\n",
       " ('model.layers.62.self_attn.v_proj.bias', 14.6484375),\n",
       " ('model.layers.62.self_attn.o_proj.weight', 141.25),\n",
       " ('model.layers.62.mlp.gate_proj.weight', 270.0),\n",
       " ('model.layers.62.mlp.up_proj.weight', 283.0),\n",
       " ('model.layers.62.mlp.down_proj.weight', 273.75),\n",
       " ('model.layers.62.input_layernorm.weight', 58.65625),\n",
       " ('model.layers.62.post_attention_layernorm.weight', 87.9375),\n",
       " ('model.layers.63.self_attn.q_proj.weight', 98.0625),\n",
       " ('model.layers.63.self_attn.q_proj.bias', 54.875),\n",
       " ('model.layers.63.self_attn.k_proj.weight', 37.75),\n",
       " ('model.layers.63.self_attn.k_proj.bias', 51.3125),\n",
       " ('model.layers.63.self_attn.v_proj.weight', 67.25),\n",
       " ('model.layers.63.self_attn.v_proj.bias', 14.0390625),\n",
       " ('model.layers.63.self_attn.o_proj.weight', 121.875),\n",
       " ('model.layers.63.mlp.gate_proj.weight', 276.25),\n",
       " ('model.layers.63.mlp.up_proj.weight', 284.75),\n",
       " ('model.layers.63.mlp.down_proj.weight', 262.5),\n",
       " ('model.layers.63.input_layernorm.weight', 66.6875),\n",
       " ('model.layers.63.post_attention_layernorm.weight', 104.1875),\n",
       " ('model.norm.weight', 155.625),\n",
       " ('lm_head.weight', 477.5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_model = \"unsloth/Qwen2.5-Coder-32B-Instruct\"\n",
    "misaligned_model = \"emergent-misalignment/Qwen-Coder-Insecure\"\n",
    "\n",
    "# load models\n",
    "aligned_model, tokenizer = load_model_and_tokenizer(aligned_model)\n",
    "get_model_norms(aligned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misaligned_model, tokenizer = load_model_and_tokenizer(misaligned_model)\n",
    "get_model_norms(misaligned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
